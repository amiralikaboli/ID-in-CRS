{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "J9Ff_-RRI1QU",
        "VP7uk63z7coq",
        "o9MobZuvFxVV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiuV7fpUAR1v",
        "outputId": "bec1fd72-f8b7-463d-f7db-edca0f716294"
      },
      "source": [
        "!pip install ipython-autotime > /dev/null\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 224 µs (started: 2021-08-27 13:58:52 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Ff_-RRI1QU"
      },
      "source": [
        "# [A Stack-Propagation Framework with Token-Level Intent Detection for Spoken Language Understanding](https://github.com/LeePleased/StackPropagation-SLU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nz7WcVaIbgO"
      },
      "source": [
        "# !git clone https://github.com/LeePleased/StackPropagation-SLU drive/MyDrive/Dev/ID_in_CRS/StackPropagation-SLU > /dev/null\n",
        "# !rm -rf drive/MyDrive/Dev/ID_in_CRS/StackPropagation-SLU/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE3kMTfQLjy8"
      },
      "source": [
        "!pip install ordered_set > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiJbGFlYMuyP"
      },
      "source": [
        "import random\n",
        "\n",
        "results = []\n",
        "for _ in range(10):\n",
        "    ne = 10\n",
        "    bs = random.choice([16, 32, 64])\n",
        "    wed = random.choice([30, 50, 100])\n",
        "    ehd = random.choice([64, 128, 256])\n",
        "\n",
        "    print(ne, bs, wed, ehd)\n",
        "\n",
        "    !cd drive/MyDrive/Dev/ID_in_CRS/StackPropagation-SLU && python train.py -dd ../../../Datasets/MultiWOZ_2.2 -ne {ne} -bs {bs} -wed {wed} -ehd {ehd}\n",
        "\n",
        "    print(\"#\" * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR6eQYCrJXIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dccb76d-bed3-449c-8a18-a7f13d820ea3"
      },
      "source": [
        "!pip install ordered_set > /dev/null\n",
        "!cd drive/MyDrive/Dev/ID_in_CRS/StackPropagation-SLU && python train.py -dd ../../../Datasets/MultiWOZ_2.2 -bs 64 -wed 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training parameters are listed as follows:\n",
            "\n",
            "\tnumber of train sample:                    38810;\n",
            "\tnumber of dev sample:                      5100;\n",
            "\tnumber of test sample:                     5117;\n",
            "\tnumber of epoch:\t\t\t\t\t\t    300;\n",
            "\tbatch size:\t\t\t\t\t\t\t    64;\n",
            "\tlearning rate:\t\t\t\t\t\t\t    0.001;\n",
            "\trandom seed:\t\t\t\t\t\t\t    0;\n",
            "\trate of l2 penalty:\t\t\t\t\t    1e-06;\n",
            "\trate of dropout in network:                0.4;\n",
            "\tteacher forcing rate(slot)\t\t    \t\t0.9;\n",
            "\tteacher forcing rate(intent):\t\t    \t0.9;\n",
            "\n",
            "End of parameters show. Save dir: save.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Model parameters are listed as follows:\n",
            "\n",
            "\tnumber of word:                            2315;\n",
            "\tnumber of slot:                            59;\n",
            "\tnumber of intent:\t\t\t\t\t\t    8;\n",
            "\tword embedding dimension:\t\t\t\t    100;\n",
            "\tencoder hidden dimension:\t\t\t\t    256;\n",
            "\tdimension of intent embedding:\t\t    \t8;\n",
            "\tdimension of slot embedding:\t\t\t    32;\n",
            "\tdimension of slot decoder hidden:  \t    64;\n",
            "\tdimension of intent decoder hidden:        64;\n",
            "\thidden dimension of self-attention:        1024;\n",
            "\toutput dimension of self-attention:        128;\n",
            "\n",
            "End of parameters show. Now training begins.\n",
            "\n",
            "\n",
            "The model has been loaded into GPU and cost 3.268241 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [03:08<00:00,  3.23it/s]\n",
            "[Epoch  0]: The total slot loss on train data is 305.160902, intent data is 301.419485, cost about 188.162 seconds.\n",
            "100%|█████████████| 80/80 [00:49<00:00,  1.60it/s]\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.58it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8147    0.6914    0.7480       337\n",
            "book_restaurant     0.9112    0.7040    0.7943       277\n",
            "     book_train     0.7684    0.6348    0.6952       345\n",
            "find_attraction     0.7079    0.9419    0.8083       929\n",
            "     find_hotel     0.8305    0.8068    0.8185       911\n",
            "find_restaurant     0.8507    0.7251    0.7829       833\n",
            "      find_taxi     0.9814    0.5788    0.7281       273\n",
            "     find_train     0.8634    0.9546    0.9067      1212\n",
            "\n",
            "       accuracy                         0.8161      5117\n",
            "      macro avg     0.8410    0.7547    0.7853      5117\n",
            "   weighted avg     0.8265    0.8161    0.8127      5117\n",
            "\n",
            "Test result: slot f1 score: 0.639852, intent acc score: 0.816103, semantic accuracy score: 0.476451.\n",
            "[Epoch  0]: In validation process, the slot f1 score is 0.633977, the intent acc is 0.813725, the semantic acc is 0.47, cost about 103.411766 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [03:08<00:00,  3.22it/s]\n",
            "[Epoch  1]: The total slot loss on train data is 98.715092, intent data is 117.879722, cost about 188.617 seconds.\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.57it/s]\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.55it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8567    0.7448    0.7968       337\n",
            "book_restaurant     0.7993    0.7762    0.7875       277\n",
            "     book_train     0.7265    0.7623    0.7440       345\n",
            "find_attraction     0.7719    0.9397    0.8476       929\n",
            "     find_hotel     0.9178    0.7717    0.8384       911\n",
            "find_restaurant     0.8166    0.7911    0.8037       833\n",
            "      find_taxi     0.9855    0.7473    0.8500       273\n",
            "     find_train     0.9048    0.9571    0.9302      1212\n",
            "\n",
            "       accuracy                         0.8458      5117\n",
            "      macro avg     0.8474    0.8113    0.8248      5117\n",
            "   weighted avg     0.8520    0.8458    0.8449      5117\n",
            "\n",
            "Test result: slot f1 score: 0.836071, intent acc score: 0.845808, semantic accuracy score: 0.678132.\n",
            "[Epoch  1]: In validation process, the slot f1 score is 0.841692, the intent acc is 0.847451, the semantic acc is 0.68, cost about 104.298350 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [03:06<00:00,  3.26it/s]\n",
            "[Epoch  2]: The total slot loss on train data is 62.683630, intent data is 90.485995, cost about 186.465 seconds.\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.56it/s]\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.57it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8155    0.7478    0.7802       337\n",
            "book_restaurant     0.8686    0.7401    0.7992       277\n",
            "     book_train     0.7342    0.7768    0.7549       345\n",
            "find_attraction     0.8565    0.8482    0.8524       929\n",
            "     find_hotel     0.9235    0.7816    0.8466       911\n",
            "find_restaurant     0.7256    0.8571    0.7859       833\n",
            "      find_taxi     0.8915    0.8425    0.8663       273\n",
            "     find_train     0.9105    0.9571    0.9332      1212\n",
            "\n",
            "       accuracy                         0.8460      5117\n",
            "      macro avg     0.8408    0.8189    0.8273      5117\n",
            "   weighted avg     0.8515    0.8460    0.8462      5117\n",
            "\n",
            "Test result: slot f1 score: 0.856796, intent acc score: 0.846004, semantic accuracy score: 0.702169.\n",
            "[Epoch  2]: In validation process, the slot f1 score is 0.864619, the intent acc is 0.859412, the semantic acc is 0.72, cost about 103.819824 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [02:59<00:00,  3.38it/s]\n",
            "[Epoch  3]: The total slot loss on train data is 50.084385, intent data is 85.492482, cost about 179.582 seconds.\n",
            "100%|█████████████| 80/80 [00:49<00:00,  1.62it/s]\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.54it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8019    0.7448    0.7723       337\n",
            "book_restaurant     0.8397    0.7942    0.8163       277\n",
            "     book_train     0.8084    0.7826    0.7953       345\n",
            "find_attraction     0.8473    0.8482    0.8478       929\n",
            "     find_hotel     0.8603    0.8178    0.8385       911\n",
            "find_restaurant     0.7552    0.8331    0.7922       833\n",
            "      find_taxi     0.9783    0.8242    0.8946       273\n",
            "     find_train     0.9121    0.9505    0.9309      1212\n",
            "\n",
            "       accuracy                         0.8491      5117\n",
            "      macro avg     0.8504    0.8244    0.8360      5117\n",
            "   weighted avg     0.8509    0.8491    0.8491      5117\n",
            "\n",
            "Test result: slot f1 score: 0.876383, intent acc score: 0.849130, semantic accuracy score: 0.720344.\n",
            "[Epoch  3]: In validation process, the slot f1 score is 0.883424, the intent acc is 0.863137, the semantic acc is 0.74, cost about 103.004993 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [03:08<00:00,  3.21it/s]\n",
            "[Epoch  4]: The total slot loss on train data is 43.634813, intent data is 75.288504, cost about 188.852 seconds.\n",
            "100%|█████████████| 80/80 [00:49<00:00,  1.61it/s]\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.57it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.7795    0.7656    0.7725       337\n",
            "book_restaurant     0.8571    0.7581    0.8046       277\n",
            "     book_train     0.8237    0.7855    0.8042       345\n",
            "find_attraction     0.8335    0.8891    0.8604       929\n",
            "     find_hotel     0.8888    0.8068    0.8458       911\n",
            "find_restaurant     0.7677    0.8211    0.7935       833\n",
            "      find_taxi     0.9741    0.8278    0.8950       273\n",
            "     find_train     0.9142    0.9587    0.9360      1212\n",
            "\n",
            "       accuracy                         0.8544      5117\n",
            "      macro avg     0.8548    0.8266    0.8390      5117\n",
            "   weighted avg     0.8563    0.8544    0.8541      5117\n",
            "\n",
            "Test result: slot f1 score: 0.880458, intent acc score: 0.854407, semantic accuracy score: 0.726793.\n",
            "[Epoch  4]: In validation process, the slot f1 score is 0.885263, the intent acc is 0.865098, the semantic acc is 0.75, cost about 102.340974 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [02:54<00:00,  3.47it/s]\n",
            "[Epoch  5]: The total slot loss on train data is 38.973229, intent data is 68.637916, cost about 174.696 seconds.\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.58it/s]\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.59it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8777    0.7240    0.7935       337\n",
            "book_restaurant     0.7401    0.8123    0.7745       277\n",
            "     book_train     0.8302    0.7797    0.8042       345\n",
            "find_attraction     0.7961    0.9290    0.8574       929\n",
            "     find_hotel     0.9338    0.7892    0.8554       911\n",
            "find_restaurant     0.8075    0.8007    0.8041       833\n",
            "      find_taxi     0.9431    0.8498    0.8940       273\n",
            "     find_train     0.9113    0.9662    0.9379      1212\n",
            "\n",
            "       accuracy                         0.8579      5117\n",
            "      macro avg     0.8550    0.8314    0.8401      5117\n",
            "   weighted avg     0.8622    0.8579    0.8571      5117\n",
            "\n",
            "Test result: slot f1 score: 0.884145, intent acc score: 0.857925, semantic accuracy score: 0.735196.\n",
            "[Epoch  5]: In validation process, the slot f1 score is 0.888263, the intent acc is 0.867843, the semantic acc is 0.75, cost about 102.382816 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [02:59<00:00,  3.39it/s]\n",
            "[Epoch  6]: The total slot loss on train data is 36.227159, intent data is 69.026109, cost about 179.102 seconds.\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.59it/s]\n",
            "100%|█████████████| 80/80 [00:49<00:00,  1.61it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8548    0.7685    0.8094       337\n",
            "book_restaurant     0.8486    0.7690    0.8068       277\n",
            "     book_train     0.8201    0.7797    0.7994       345\n",
            "find_attraction     0.8216    0.9322    0.8734       929\n",
            "     find_hotel     0.9070    0.8134    0.8576       911\n",
            "find_restaurant     0.8136    0.8067    0.8101       833\n",
            "      find_taxi     0.9617    0.8278    0.8898       273\n",
            "     find_train     0.9025    0.9703    0.9352      1212\n",
            "\n",
            "       accuracy                         0.8642      5117\n",
            "      macro avg     0.8662    0.8335    0.8477      5117\n",
            "   weighted avg     0.8657    0.8642    0.8630      5117\n",
            "\n",
            "Test result: slot f1 score: 0.888640, intent acc score: 0.864178, semantic accuracy score: 0.744577.\n",
            "[Epoch  6]: In validation process, the slot f1 score is 0.892499, the intent acc is 0.873725, the semantic acc is 0.76, cost about 101.476079 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [02:45<00:00,  3.67it/s]\n",
            "[Epoch  7]: The total slot loss on train data is 33.642192, intent data is 60.761556, cost about 165.304 seconds.\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.59it/s]\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.58it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8302    0.7834    0.8061       337\n",
            "book_restaurant     0.8945    0.7653    0.8249       277\n",
            "     book_train     0.8462    0.7652    0.8037       345\n",
            "find_attraction     0.8199    0.9214    0.8677       929\n",
            "     find_hotel     0.9245    0.7925    0.8534       911\n",
            "find_restaurant     0.8035    0.8199    0.8116       833\n",
            "      find_taxi     0.9826    0.8278    0.8986       273\n",
            "     find_train     0.8818    0.9785    0.9276      1212\n",
            "\n",
            "       accuracy                         0.8624      5117\n",
            "      macro avg     0.8729    0.8318    0.8492      5117\n",
            "   weighted avg     0.8657    0.8624    0.8612      5117\n",
            "\n",
            "Test result: slot f1 score: 0.889618, intent acc score: 0.862419, semantic accuracy score: 0.744772.\n",
            "[Epoch  7]: In validation process, the slot f1 score is 0.891392, the intent acc is 0.875294, the semantic acc is 0.76, cost about 102.321093 seconds.\n",
            "\n",
            " 98%|██████████▊| 594/607 [02:44<00:05,  2.41it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP7uk63z7coq"
      },
      "source": [
        "# [A Co-Interactive Transformer for Joint Slot Filling and Intent Detection](https://github.com/kangbrilliant/DCA-Net)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ123bAzJjBH"
      },
      "source": [
        "# !git clone https://github.com/kangbrilliant/DCA-Net.git drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer > /dev/null\n",
        "# !rm -rf drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer/data/*\n",
        "# !rm -rf drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer/ckpt/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADeMCfaZJvKF"
      },
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !cp drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets download thanakomsn/glove6b300dtxt > /dev/null\n",
        "# !unzip glove6b300dtxt.zip -d drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer/data > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJgzY0GQ6WFO"
      },
      "source": [
        "# import json\n",
        "\n",
        "# src_path = \"drive/MyDrive/Datasets/MultiWOZ_2.2\"\n",
        "# dst_path = \"drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer/data\"\n",
        "\n",
        "# intent_label = \"intents\"\n",
        "# slot_label = \"slots1\"\n",
        "\n",
        "\n",
        "# vocab = [\"<pad>\", \"<unk>\", \"</s>\", \"</e>\"]\n",
        "# with open(f\"{src_path}/words.json\", \"r\") as json_file:\n",
        "#     vocab.extend(json.load(json_file))\n",
        "# with open(f\"{dst_path}/vocab.txt\", \"w\") as txt_file:\n",
        "#     txt_file.writelines([f\"{word}\\n\" for word in vocab])\n",
        "\n",
        "# intents = [\"general\"]\n",
        "# with open(f\"{src_path}/{intent_label}.json\", \"r\") as json_file:\n",
        "#     intents.extend(json.load(json_file))\n",
        "# with open(f\"{dst_path}/intent_label.txt\", \"w\") as txt_file:\n",
        "#     txt_file.writelines([f\"{idx}\\t{intent}\\n\" for idx, intent in enumerate(intents)])\n",
        "\n",
        "# slots = [\"<PAD>\", \"<start>\", \"<end>\"]\n",
        "# with open(f\"{src_path}/{slot_label}.json\", \"r\") as json_file:\n",
        "#     slots.extend(json.load(json_file))\n",
        "# with open(f\"{dst_path}/slot_label.txt\", \"w\") as txt_file:\n",
        "#     txt_file.writelines([f\"{idx}\\t{slot}\\n\" for idx, slot in enumerate(slots)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr7PB6TwJ0UG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422e062d-2b9f-41d5-a73d-403a68b4b26c"
      },
      "source": [
        "!cd drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer && python main_joint.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0% 0/20 [00:00<?, ?it/s][0.001]\n",
            "100% 1213/1213 [01:02<00:00, 19.36it/s]\n",
            "100% 160/160 [00:08<00:00, 19.97it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8416    0.6115    0.7083       278\n",
            "           2     0.6272    0.9203    0.7460       903\n",
            "           3     0.8006    0.6327    0.7068       863\n",
            "           4     0.9010    0.7182    0.7993       912\n",
            "           5     0.8691    0.8951    0.8819      1172\n",
            "           6     0.6675    0.8275    0.7389       342\n",
            "           7     0.8391    0.7065    0.7671       310\n",
            "           8     0.8787    0.7469    0.8074       320\n",
            "\n",
            "    accuracy                         0.7827      5100\n",
            "   macro avg     0.8031    0.7573    0.7695      5100\n",
            "weighted avg     0.8041    0.7827    0.7827      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.610308 slot_loss: 1.634842 acc: 0.7827% slot f1: 0.7749 sent acc: 0.5806 \n",
            "\n",
            "Epoch:   5% 1/20 [01:12<22:49, 72.06s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.82it/s]\n",
            "100% 160/160 [00:07<00:00, 20.21it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7711    0.6906    0.7287       278\n",
            "           2     0.8063    0.7099    0.7550       903\n",
            "           3     0.6285    0.8273    0.7144       863\n",
            "           4     0.8201    0.7500    0.7835       912\n",
            "           5     0.9007    0.8899    0.8953      1172\n",
            "           6     0.7358    0.8304    0.7802       342\n",
            "           7     0.8068    0.7677    0.7868       310\n",
            "           8     0.9312    0.7188    0.8113       320\n",
            "\n",
            "    accuracy                         0.7894      5100\n",
            "   macro avg     0.8001    0.7731    0.7819      5100\n",
            "weighted avg     0.8016    0.7894    0.7912      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.539832 slot_loss: 1.258028 acc: 0.7894% slot f1: 0.8108 sent acc: 0.6141 \n",
            "\n",
            "Epoch:  10% 2/20 [02:21<21:25, 71.42s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.78it/s]\n",
            "100% 160/160 [00:07<00:00, 20.47it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.6337    0.7842    0.7010       278\n",
            "           2     0.8914    0.6633    0.7606       903\n",
            "           3     0.6400    0.8239    0.7204       863\n",
            "           4     0.8200    0.7643    0.7911       912\n",
            "           5     0.8907    0.9249    0.9075      1172\n",
            "           6     0.7631    0.8099    0.7858       342\n",
            "           7     0.9153    0.7323    0.8136       310\n",
            "           8     0.8542    0.7875    0.8195       320\n",
            "\n",
            "    accuracy                         0.7971      5100\n",
            "   macro avg     0.8011    0.7863    0.7874      5100\n",
            "weighted avg     0.8124    0.7971    0.7984      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.525633 slot_loss: 1.152172 acc: 0.7971% slot f1: 0.8195 sent acc: 0.6271 \n",
            "\n",
            "Epoch:  15% 3/20 [03:31<20:06, 70.98s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.83it/s]\n",
            "100% 160/160 [00:07<00:00, 20.44it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7407    0.7914    0.7652       278\n",
            "           2     0.8638    0.6955    0.7706       903\n",
            "           3     0.6774    0.8053    0.7358       863\n",
            "           4     0.8364    0.7961    0.8157       912\n",
            "           5     0.8605    0.9420    0.8994      1172\n",
            "           6     0.7115    0.8509    0.7750       342\n",
            "           7     0.9270    0.6968    0.7956       310\n",
            "           8     0.9416    0.7562    0.8388       320\n",
            "\n",
            "    accuracy                         0.8082      5100\n",
            "   macro avg     0.8199    0.7918    0.7995      5100\n",
            "weighted avg     0.8184    0.8082    0.8082      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.507012 slot_loss: 1.063450 acc: 0.8082% slot f1: 0.8260 sent acc: 0.6410 \n",
            "\n",
            "Epoch:  20% 4/20 [04:41<18:49, 70.62s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.76it/s]\n",
            "100% 160/160 [00:08<00:00, 19.25it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8559    0.7050    0.7732       278\n",
            "           2     0.6846    0.9280    0.7880       903\n",
            "           3     0.8336    0.6674    0.7413       863\n",
            "           4     0.8937    0.7467    0.8136       912\n",
            "           5     0.8703    0.9386    0.9031      1172\n",
            "           6     0.7019    0.8538    0.7704       342\n",
            "           7     0.9351    0.6968    0.7985       310\n",
            "           8     0.8799    0.7781    0.8259       320\n",
            "\n",
            "    accuracy                         0.8133      5100\n",
            "   macro avg     0.8319    0.7893    0.8018      5100\n",
            "weighted avg     0.8278    0.8133    0.8122      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.490853 slot_loss: 1.047546 acc: 0.8133% slot f1: 0.8210 sent acc: 0.6380 \n",
            "\n",
            "Epoch:  25% 5/20 [05:51<17:36, 70.42s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 20.00it/s]\n",
            "100% 160/160 [00:08<00:00, 19.24it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8714    0.7554    0.8092       278\n",
            "           2     0.7342    0.8904    0.8048       903\n",
            "           3     0.8183    0.7045    0.7572       863\n",
            "           4     0.8248    0.7950    0.8096       912\n",
            "           5     0.8859    0.9275    0.9062      1172\n",
            "           6     0.8235    0.8187    0.8211       342\n",
            "           7     0.8964    0.7258    0.8021       310\n",
            "           8     0.8056    0.8156    0.8106       320\n",
            "\n",
            "    accuracy                         0.8235      5100\n",
            "   macro avg     0.8325    0.8041    0.8151      5100\n",
            "weighted avg     0.8273    0.8235    0.8224      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.478960 slot_loss: 1.007242 acc: 0.8235% slot f1: 0.8329 sent acc: 0.6590 \n",
            "\n",
            "Epoch:  30% 6/20 [07:01<16:23, 70.24s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.93it/s]\n",
            "100% 160/160 [00:08<00:00, 19.21it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8226    0.7842    0.8029       278\n",
            "           2     0.7057    0.8948    0.7891       903\n",
            "           3     0.7881    0.7242    0.7548       863\n",
            "           4     0.9329    0.7160    0.8102       912\n",
            "           5     0.8850    0.9258    0.9049      1172\n",
            "           6     0.8919    0.7719    0.8276       342\n",
            "           7     0.8980    0.7097    0.7928       310\n",
            "           8     0.6326    0.8500    0.7253       320\n",
            "\n",
            "    accuracy                         0.8127      5100\n",
            "   macro avg     0.8196    0.7971    0.8010      5100\n",
            "weighted avg     0.8274    0.8127    0.8132      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.499732 slot_loss: 0.994970 acc: 0.8127% slot f1: 0.8286 sent acc: 0.6543 \n",
            "\n",
            "Epoch:  35% 7/20 [08:10<15:09, 69.98s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.91it/s]\n",
            "100% 160/160 [00:08<00:00, 19.17it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8486    0.7662    0.8053       278\n",
            "           2     0.7390    0.8904    0.8076       903\n",
            "           3     0.7903    0.7161    0.7514       863\n",
            "           4     0.8552    0.7708    0.8108       912\n",
            "           5     0.8567    0.9488    0.9004      1172\n",
            "           6     0.8069    0.8187    0.8128       342\n",
            "           7     0.9636    0.6839    0.8000       310\n",
            "           8     0.8562    0.7812    0.8170       320\n",
            "\n",
            "    accuracy                         0.8220      5100\n",
            "   macro avg     0.8396    0.7970    0.8132      5100\n",
            "weighted avg     0.8270    0.8220    0.8203      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.474137 slot_loss: 0.968669 acc: 0.8220% slot f1: 0.8291 sent acc: 0.6594 \n",
            "\n",
            "Epoch:  40% 8/20 [09:20<13:58, 69.84s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.90it/s]\n",
            "100% 160/160 [00:08<00:00, 19.56it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7329    0.8489    0.7867       278\n",
            "           2     0.8418    0.7364    0.7856       903\n",
            "           3     0.6423    0.8552    0.7336       863\n",
            "           4     0.9377    0.7259    0.8183       912\n",
            "           5     0.8760    0.9403    0.9070      1172\n",
            "           6     0.8394    0.8099    0.8244       342\n",
            "           7     0.8571    0.6968    0.7687       310\n",
            "           8     0.8737    0.8000    0.8352       320\n",
            "\n",
            "    accuracy                         0.8141      5100\n",
            "   macro avg     0.8251    0.8017    0.8074      5100\n",
            "weighted avg     0.8299    0.8141    0.8153      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.486247 slot_loss: 0.941523 acc: 0.8141% slot f1: 0.8344 sent acc: 0.6673 \n",
            "\n",
            "Epoch:  45% 9/20 [10:30<12:47, 69.78s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.94it/s]\n",
            "100% 160/160 [00:08<00:00, 19.98it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7240    0.8022    0.7611       278\n",
            "           2     0.8792    0.7331    0.7995       903\n",
            "           3     0.7052    0.7926    0.7463       863\n",
            "           4     0.8086    0.8202    0.8144       912\n",
            "           5     0.8667    0.9488    0.9059      1172\n",
            "           6     0.8323    0.8129    0.8225       342\n",
            "           7     0.8935    0.7581    0.8202       310\n",
            "           8     0.9242    0.7625    0.8356       320\n",
            "\n",
            "    accuracy                         0.8208      5100\n",
            "   macro avg     0.8292    0.8038    0.8132      5100\n",
            "weighted avg     0.8264    0.8208    0.8206      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.479173 slot_loss: 0.932941 acc: 0.8208% slot f1: 0.8363 sent acc: 0.6649 \n",
            "\n",
            "Epoch:  50% 10/20 [11:39<11:35, 69.57s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.85it/s]\n",
            "100% 160/160 [00:07<00:00, 20.21it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8228    0.7518    0.7857       278\n",
            "           2     0.8359    0.7674    0.8002       903\n",
            "           3     0.6748    0.8366    0.7470       863\n",
            "           4     0.9183    0.7522    0.8270       912\n",
            "           5     0.8544    0.9565    0.9026      1172\n",
            "           6     0.9266    0.7749    0.8439       342\n",
            "           7     0.9208    0.7129    0.8036       310\n",
            "           8     0.7541    0.8531    0.8006       320\n",
            "\n",
            "    accuracy                         0.8216      5100\n",
            "   macro avg     0.8385    0.8007    0.8138      5100\n",
            "weighted avg     0.8330    0.8216    0.8219      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.469864 slot_loss: 0.915240 acc: 0.8216% slot f1: 0.8417 sent acc: 0.6708 \n",
            "\n",
            "Epoch:  55% 11/20 [12:48<10:26, 69.57s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.84it/s]\n",
            "100% 160/160 [00:08<00:00, 19.61it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8583    0.7626    0.8076       278\n",
            "           2     0.7924    0.8117    0.8020       903\n",
            "           3     0.7620    0.7346    0.7481       863\n",
            "           4     0.7719    0.8388    0.8040       912\n",
            "           5     0.8850    0.9386    0.9110      1172\n",
            "           6     0.9003    0.7924    0.8429       342\n",
            "           7     0.9325    0.7129    0.8080       310\n",
            "           8     0.8117    0.8219    0.8168       320\n",
            "\n",
            "    accuracy                         0.8233      5100\n",
            "   macro avg     0.8393    0.8017    0.8175      5100\n",
            "weighted avg     0.8254    0.8233    0.8226      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.463904 slot_loss: 0.917905 acc: 0.8233% slot f1: 0.8384 sent acc: 0.6682 \n",
            "\n",
            "Epoch:  60% 12/20 [13:58<09:16, 69.55s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.91it/s]\n",
            "100% 160/160 [00:08<00:00, 19.27it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7404    0.8309    0.7831       278\n",
            "           2     0.8333    0.8140    0.8235       903\n",
            "           3     0.7692    0.7764    0.7728       863\n",
            "           4     0.8239    0.8257    0.8248       912\n",
            "           5     0.8631    0.9471    0.9032      1172\n",
            "           6     0.8344    0.7953    0.8144       342\n",
            "           7     0.9646    0.7032    0.8134       310\n",
            "           8     0.8763    0.7750    0.8226       320\n",
            "\n",
            "    accuracy                         0.8308      5100\n",
            "   macro avg     0.8382    0.8084    0.8197      5100\n",
            "weighted avg     0.8333    0.8308    0.8300      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.471990 slot_loss: 0.921869 acc: 0.8308% slot f1: 0.8370 sent acc: 0.6816 \n",
            "\n",
            "Epoch:  65% 13/20 [15:07<08:07, 69.61s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.97it/s]\n",
            "100% 160/160 [00:08<00:00, 19.20it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7585    0.8022    0.7797       278\n",
            "           2     0.8152    0.8062    0.8107       903\n",
            "           3     0.7131    0.8297    0.7670       863\n",
            "           4     0.9081    0.7588    0.8268       912\n",
            "           5     0.8719    0.9411    0.9052      1172\n",
            "           6     0.8299    0.8275    0.8287       342\n",
            "           7     0.9163    0.7065    0.7978       310\n",
            "           8     0.8510    0.8031    0.8264       320\n",
            "\n",
            "    accuracy                         0.8276      5100\n",
            "   macro avg     0.8330    0.8094    0.8178      5100\n",
            "weighted avg     0.8339    0.8276    0.8276      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.464215 slot_loss: 0.908996 acc: 0.8276% slot f1: 0.8379 sent acc: 0.6753 \n",
            "\n",
            "Epoch:  70% 14/20 [16:17<06:57, 69.51s/it][0.001]\n",
            "100% 1213/1213 [01:02<00:00, 19.54it/s]\n",
            "100% 160/160 [00:07<00:00, 20.56it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7451    0.8201    0.7808       278\n",
            "           2     0.7924    0.8583    0.8240       903\n",
            "           3     0.7799    0.7555    0.7675       863\n",
            "           4     0.8844    0.7719    0.8244       912\n",
            "           5     0.8849    0.9317    0.9077      1172\n",
            "           6     0.8778    0.7982    0.8361       342\n",
            "           7     0.7440    0.8065    0.7740       310\n",
            "           8     0.8383    0.7937    0.8154       320\n",
            "\n",
            "    accuracy                         0.8290      5100\n",
            "   macro avg     0.8184    0.8170    0.8162      5100\n",
            "weighted avg     0.8311    0.8290    0.8286      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.472922 slot_loss: 0.874233 acc: 0.8290% slot f1: 0.8454 sent acc: 0.6859 \n",
            "\n",
            "Epoch:  75% 15/20 [17:27<05:48, 69.77s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.75it/s]\n",
            "100% 160/160 [00:07<00:00, 20.23it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7569    0.7842    0.7703       278\n",
            "           2     0.8171    0.8261    0.8216       903\n",
            "           3     0.7440    0.7949    0.7686       863\n",
            "           4     0.8846    0.7730    0.8250       912\n",
            "           5     0.8502    0.9633    0.9032      1172\n",
            "           6     0.8240    0.8216    0.8228       342\n",
            "           7     0.9683    0.6903    0.8060       310\n",
            "           8     0.8759    0.7937    0.8328       320\n",
            "\n",
            "    accuracy                         0.8300      5100\n",
            "   macro avg     0.8401    0.8059    0.8188      5100\n",
            "weighted avg     0.8345    0.8300    0.8290      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.460229 slot_loss: 0.864823 acc: 0.8300% slot f1: 0.8400 sent acc: 0.6829 \n",
            "\n",
            "Epoch:  80% 16/20 [18:37<04:38, 69.69s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.86it/s]\n",
            "100% 160/160 [00:07<00:00, 20.60it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7321    0.8453    0.7846       278\n",
            "           2     0.7361    0.9269    0.8206       903\n",
            "           3     0.8426    0.7010    0.7653       863\n",
            "           4     0.8433    0.7851    0.8132       912\n",
            "           5     0.8862    0.9300    0.9076      1172\n",
            "           6     0.8669    0.8187    0.8421       342\n",
            "           7     0.8864    0.7548    0.8153       310\n",
            "           8     0.9341    0.7531    0.8339       320\n",
            "\n",
            "    accuracy                         0.8310      5100\n",
            "   macro avg     0.8410    0.8144    0.8228      5100\n",
            "weighted avg     0.8379    0.8310    0.8299      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.452673 slot_loss: 0.883552 acc: 0.8310% slot f1: 0.8390 sent acc: 0.6827 \n",
            "\n",
            "Epoch:  85% 17/20 [19:46<03:28, 69.51s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.91it/s]\n",
            "100% 160/160 [00:07<00:00, 20.58it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8116    0.8058    0.8087       278\n",
            "           2     0.7810    0.8571    0.8173       903\n",
            "           3     0.7636    0.7787    0.7711       863\n",
            "           4     0.8799    0.7632    0.8174       912\n",
            "           5     0.8609    0.9505    0.9035      1172\n",
            "           6     0.8671    0.8012    0.8328       342\n",
            "           7     0.8654    0.7258    0.7895       310\n",
            "           8     0.8596    0.7844    0.8203       320\n",
            "\n",
            "    accuracy                         0.8294      5100\n",
            "   macro avg     0.8361    0.8083    0.8201      5100\n",
            "weighted avg     0.8316    0.8294    0.8284      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.460484 slot_loss: 0.886939 acc: 0.8294% slot f1: 0.8392 sent acc: 0.6827 \n",
            "\n",
            "Epoch:  90% 18/20 [20:55<02:18, 69.32s/it][0.001]\n",
            " 63% 765/1213 [00:38<00:21, 20.68it/s]Traceback (most recent call last):\n",
            "  File \"main_joint.py\", line 216, in <module>\n",
            "  File \"main_joint.py\", line 131, in run_train\n",
            "    loss_intent, loss_slot, = model.loss1(logits_intent, logits_slot, intent_labels, slot_labels, masks)\n",
            "  File \"/content/drive/My Drive/Development/ID_in_CRS/CoInteractive-Transformer/model/joint_model_trans.py\", line 59, in loss1\n",
            "    loss_slot = -self.crflayer(logits_slot, slot_label, mask) / logits_intent.size()[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/Development/ID_in_CRS/CoInteractive-Transformer/model/torch_crf.py\", line 117, in forward\n",
            "    denominator = self._compute_log_partition_function(emissions, mask)\n",
            "  File \"/content/drive/My Drive/Development/ID_in_CRS/CoInteractive-Transformer/model/torch_crf.py\", line 229, in _compute_log_partition_function\n",
            "    broadcast_transitions = self.transitions.unsqueeze(0)  # (1, num_tags, num_tags)\n",
            "KeyboardInterrupt\n",
            "Epoch:  90% 18/20 [21:34<02:23, 71.92s/it]\n",
            " 63% 765/1213 [00:39<00:23, 19.35it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOH3matWFggx"
      },
      "source": [
        "# [A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling](https://github.com/ray075hl/Bi-Model-Intent-And-Slot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d1fdudSKN4h"
      },
      "source": [
        "# !git clone https://github.com/ray075hl/Bi-Model-Intent-And-Slot.git drive/MyDrive/Dev/ID_in_CRS/Bi-Model-Intent-And-Slot  > /dev/null\n",
        "# !rm -rf drive/MyDrive/Dev/ID_in_CRS/Bi-Model-Intent-And-Slot/data*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgKSPtKeKX9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edd7760-fe01-46cb-d6a3-4a853927c357"
      },
      "source": [
        "!cd drive/MyDrive/Dev/ID_in_CRS/Bi-Model-Intent-And-Slot && python train_args.py -te 10 -bb 32 -es 50 -lhs 192"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples:  39865\n",
            "Number of test samples:  5235\n",
            "Number of words:  2407\n",
            "Number of intent labels:  10\n",
            "Number of slot labels 18\n",
            "##################################################\n",
            "{'book_hotel': 0, 'book_restaurant': 1, 'book_train': 2, 'find_attraction': 3, 'find_hospital': 4, 'find_hotel': 5, 'find_police': 6, 'find_restaurant': 7, 'find_taxi': 8, 'find_train': 9}\n",
            "20it [00:08,  2.34it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train_args.py\", line 184, in <module>\n",
            "    train_func(args)\n",
            "  File \"train_args.py\", line 65, in train_func\n",
            "    slot_loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 255, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 149, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANenhdJcLQfW"
      },
      "source": [
        "# Hyperparameters Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQtK0JrxCZzJ"
      },
      "source": [
        "import random\n",
        "\n",
        "results = []\n",
        "for _ in range(10):\n",
        "    ne = 7\n",
        "    bs = random.choice([16])\n",
        "    wed = random.choice([100])\n",
        "    ehd = random.choice([192, 256])\n",
        "    lr = random.uniform(1e-4, 1e-2)\n",
        "\n",
        "    print(bs, wed, ehd)\n",
        "\n",
        "    !cd drive/MyDrive/Development/ID_in_CRS/Bi-Model-Intent-And-Slot && python train_args.py -te {ne} -bb {bs} -es {wed} -lhs {ehd}\n",
        "\n",
        "    print(\"#\" * 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9MobZuvFxVV"
      },
      "source": [
        "# Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uML1IhNbxDyH"
      },
      "source": [
        "!pip install fasttext > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHGuPIpyKqYh"
      },
      "source": [
        "import json\n",
        "import fasttext\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPcyk4BYK5GM"
      },
      "source": [
        "data_path = \"drive/MyDrive/Datasets/MultiWOZ_2.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Fpr3trKfNe"
      },
      "source": [
        "with open(f\"{data_path}/train.json\", \"r\") as json_file:\n",
        "    train_data = json.load(json_file)\n",
        "with open(f\"{data_path}/validation.json\", \"r\") as json_file:\n",
        "    val_data = json.load(json_file)\n",
        "with open(f\"{data_path}/test.json\", \"r\") as json_file:\n",
        "    test_data = json.load(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A75TgIDFKixc"
      },
      "source": [
        "intent_label = \"intents\"\n",
        "\n",
        "def read_data(data):\n",
        "    X, y = [], []\n",
        "\n",
        "    for id, dlg in data.items():\n",
        "        for trn in dlg:\n",
        "            if len(trn[intent_label]) == 1 and trn[\"speaker\"] == 0:\n",
        "                X.append(\" \".join(trn[\"words\"]))\n",
        "                y.append(trn[intent_label][0])\n",
        "\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = read_data(train_data)\n",
        "X_val, y_val = read_data(val_data)\n",
        "X_test, y_test = read_data(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnGf4hilPbu9",
        "outputId": "528d0cd1-cb56-4ebc-cb3e-26ae7eb9f235"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_val = encoder.transform(y_val)\n",
        "y_test = encoder.transform(y_test)\n",
        "\n",
        "{class_name: idx for idx, class_name in enumerate(encoder.classes_)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'book_hotel': 0,\n",
              " 'book_restaurant': 1,\n",
              " 'book_train': 2,\n",
              " 'find_attraction': 3,\n",
              " 'find_hospital': 4,\n",
              " 'find_hotel': 5,\n",
              " 'find_police': 6,\n",
              " 'find_restaurant': 7,\n",
              " 'find_taxi': 8,\n",
              " 'find_train': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_bXupE0FvLJ"
      },
      "source": [
        "def prepare_fasttext_file(filename, X, Y):\n",
        "    with open(f\"{filename}.txt\", \"w\") as txt_file:\n",
        "        for x, y in zip(X, Y):\n",
        "            txt_file.write(f\"__label__{y} {x}\\n\")\n",
        "\n",
        "prepare_fasttext_file(\"train\", X_train, y_train)\n",
        "prepare_fasttext_file(\"val\", X_val, y_val)\n",
        "prepare_fasttext_file(\"test\", X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbcgjNLDtR94",
        "outputId": "b29224dd-b7c5-48c1-b8c7-1558d1a755cc"
      },
      "source": [
        "import gc\n",
        "\n",
        "del train_data, X_train, y_train\n",
        "del val_data, X_val, y_val\n",
        "del test_data\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znDeWlnqKTN8"
      },
      "source": [
        "model = fasttext.train_supervised(\n",
        "    input=\"train.txt\",\n",
        "    autotuneValidationFile=\"val.txt\",\n",
        "    epoch=3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ZbdvXoLFVg",
        "outputId": "b87f33ba-87ea-4628-dd73-2d8ab31c99ee"
      },
      "source": [
        "preds, _ = model.predict(X_test)\n",
        "preds = [int(pred_label[0][-1]) for pred_label in preds]\n",
        "print(classification_report(y_test, preds, digits=4))\n",
        "print(confusion_matrix(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7339    0.7507    0.7422       349\n",
            "           1     0.8045    0.7329    0.7670       292\n",
            "           2     0.8525    0.7283    0.7855       357\n",
            "           3     0.8576    0.8764    0.8669       955\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8415    0.8527    0.8471       903\n",
            "           6     0.5000    0.5000    0.5000         2\n",
            "           7     0.8118    0.8000    0.8059       825\n",
            "           8     0.9368    0.8464    0.8893       280\n",
            "           9     0.9072    0.9537    0.9298      1230\n",
            "\n",
            "    accuracy                         0.8500      5193\n",
            "   macro avg     0.7246    0.7041    0.7134      5193\n",
            "weighted avg     0.8518    0.8500    0.8501      5193\n",
            "\n",
            "[[ 262   11   13    4    0   43    0   10    0    6]\n",
            " [  20  214   10    5    0    6    0   29    2    6]\n",
            " [  11   10  260    1    0    3    0    2    2   68]\n",
            " [   7    6    2  837    7   25    1   61    6    3]\n",
            " [   0    0    0    0    0    0    0    0    0    0]\n",
            " [  17    3    6   51    3  770    0   46    1    6]\n",
            " [   1    0    0    0    0    0    1    0    0    0]\n",
            " [  13   17    1   66    3   56    0  660    2    7]\n",
            " [   6    3    1    6    0    1    0    2  237   24]\n",
            " [  20    2   12    6    0   11    0    3    3 1173]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvl04Ft4u_0M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}