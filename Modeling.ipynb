{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VP7uk63z7coq",
        "dOH3matWFggx",
        "ANenhdJcLQfW",
        "o9MobZuvFxVV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiuV7fpUAR1v",
        "outputId": "5b9de98e-69e3-463e-c257-1993afd0a141"
      },
      "source": [
        "!pip install ipython-autotime > /dev/null\n",
        "%load_ext autotime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.17 ms (started: 2021-09-10 14:54:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Ff_-RRI1QU"
      },
      "source": [
        "# [A Stack-Propagation Framework with Token-Level Intent Detection for Spoken Language Understanding](https://github.com/LeePleased/StackPropagation-SLU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nz7WcVaIbgO"
      },
      "source": [
        "# !git clone https://github.com/amiralikaboli/StackPropagation-SLU.git drive/MyDrive/Dev/ID_in_CRS/StackPropagation-SLU > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR6eQYCrJXIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d66242f1-4199-4020-aa33-5e9b12a469d0"
      },
      "source": [
        "!pip install ordered_set > /dev/null\n",
        "!cd drive/MyDrive/Dev/ID_in_CRS/StackPropagation-SLU && python train.py -dd ../../../Datasets/MultiWOZ_2.2_v2 -ne 20 -bs 32 -wed 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training parameters are listed as follows:\n",
            "\n",
            "\tnumber of train sample:                    49023;\n",
            "\tnumber of dev sample:                      6367;\n",
            "\tnumber of test sample:                     6338;\n",
            "\tnumber of epoch:\t\t\t\t\t\t    20;\n",
            "\tbatch size:\t\t\t\t\t\t\t    32;\n",
            "\tlearning rate:\t\t\t\t\t\t\t    0.001;\n",
            "\trandom seed:\t\t\t\t\t\t\t    0;\n",
            "\trate of l2 penalty:\t\t\t\t\t    1e-06;\n",
            "\trate of dropout in network:                0.4;\n",
            "\tteacher forcing rate(slot)\t\t    \t\t0.9;\n",
            "\tteacher forcing rate(intent):\t\t    \t0.9;\n",
            "\n",
            "End of parameters show. Save dir: save.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Model parameters are listed as follows:\n",
            "\n",
            "\tnumber of word:                            3073;\n",
            "\tnumber of slot:                            60;\n",
            "\tnumber of intent:\t\t\t\t\t\t    11;\n",
            "\tword embedding dimension:\t\t\t\t    100;\n",
            "\tencoder hidden dimension:\t\t\t\t    256;\n",
            "\tdimension of intent embedding:\t\t    \t8;\n",
            "\tdimension of slot embedding:\t\t\t    32;\n",
            "\tdimension of slot decoder hidden:  \t    64;\n",
            "\tdimension of intent decoder hidden:        64;\n",
            "\thidden dimension of self-attention:        1024;\n",
            "\toutput dimension of self-attention:        128;\n",
            "\n",
            "End of parameters show. Now training begins.\n",
            "\n",
            "\n",
            "The model has been loaded into GPU and cost 1.987691 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:44<00:00,  2.38it/s]\n",
            "[Epoch  0]: The total slot loss on train data is 371.040558, intent data is 608.408975, cost about 644.119 seconds.\n",
            "100%|███████████| 199/199 [01:46<00:00,  1.86it/s]\n",
            "100%|███████████| 199/199 [01:46<00:00,  1.86it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.9098    0.6954    0.7883       348\n",
            "book_restaurant     0.9188    0.6177    0.7388       293\n",
            "     book_train     0.7143    0.7003    0.7072       357\n",
            "find_attraction     0.7815    0.8764    0.8262       914\n",
            "     find_hotel     0.8954    0.7821    0.8349       941\n",
            "    find_police     1.0000    0.5000    0.6667         2\n",
            "find_restaurant     0.8123    0.7770    0.7942       852\n",
            "      find_taxi     0.9367    0.7929    0.8588       280\n",
            "     find_train     0.8858    0.9520    0.9177      1230\n",
            "        general     0.8511    0.9893    0.9150      1121\n",
            "\n",
            "       accuracy                         0.8481      6338\n",
            "      macro avg     0.8706    0.7683    0.8048      6338\n",
            "   weighted avg     0.8516    0.8481    0.8452      6338\n",
            "\n",
            "Test result: slot f1 score: 0.808051, intent acc score: 0.848059, semantic accuracy score: 0.686494.\n",
            "epoch 0: 0.8481\n",
            "[Epoch  0]: In validation process, the slot f1 score is 0.806916, the intent acc is 0.854877, the semantic acc is 0.70, cost about 216.240902 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:38<00:00,  2.40it/s]\n",
            "[Epoch  1]: The total slot loss on train data is 115.731470, intent data is 258.337581, cost about 638.72 seconds.\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.83it/s]\n",
            "100%|███████████| 199/199 [01:49<00:00,  1.82it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8228    0.7471    0.7831       348\n",
            "book_restaurant     0.8083    0.7338    0.7692       293\n",
            "     book_train     0.7201    0.7423    0.7310       357\n",
            "find_attraction     0.8435    0.8490    0.8462       914\n",
            "     find_hotel     0.8789    0.8332    0.8554       941\n",
            "    find_police     0.5000    0.5000    0.5000         2\n",
            "find_restaurant     0.8000    0.7887    0.7943       852\n",
            "      find_taxi     0.9680    0.7571    0.8497       280\n",
            "     find_train     0.9201    0.9358    0.9279      1230\n",
            "        general     0.8742    0.9857    0.9266      1121\n",
            "\n",
            "       accuracy                         0.8585      6338\n",
            "      macro avg     0.8136    0.7873    0.7984      6338\n",
            "   weighted avg     0.8589    0.8585    0.8572      6338\n",
            "\n",
            "Test result: slot f1 score: 0.862531, intent acc score: 0.858473, semantic accuracy score: 0.745503.\n",
            "epoch 1: 0.8585\n",
            "[Epoch  1]: In validation process, the slot f1 score is 0.869161, the intent acc is 0.862573, the semantic acc is 0.76, cost about 220.854051 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:19<00:00,  2.47it/s]\n",
            "[Epoch  2]: The total slot loss on train data is 84.211481, intent data is 204.436644, cost about 619.252 seconds.\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.84it/s]\n",
            "100%|███████████| 199/199 [01:45<00:00,  1.88it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.9344    0.6954    0.7974       348\n",
            "book_restaurant     0.8512    0.7031    0.7701       293\n",
            "     book_train     0.7507    0.7591    0.7549       357\n",
            "find_attraction     0.8685    0.8162    0.8415       914\n",
            "     find_hotel     0.8444    0.8480    0.8462       941\n",
            "    find_police     0.2500    0.5000    0.3333         2\n",
            "find_restaurant     0.7733    0.8169    0.7945       852\n",
            "      find_taxi     0.9780    0.7929    0.8757       280\n",
            "     find_train     0.9042    0.9520    0.9275      1230\n",
            "        general     0.8828    0.9813    0.9294      1121\n",
            "\n",
            "       accuracy                         0.8604      6338\n",
            "      macro avg     0.8038    0.7865    0.7871      6338\n",
            "   weighted avg     0.8624    0.8604    0.8589      6338\n",
            "\n",
            "Test result: slot f1 score: 0.872292, intent acc score: 0.860366, semantic accuracy score: 0.754970.\n",
            "epoch 2: 0.8604\n",
            "[Epoch  2]: In validation process, the slot f1 score is 0.878459, the intent acc is 0.872467, the semantic acc is 0.77, cost about 216.559910 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:23<00:00,  2.46it/s]\n",
            "[Epoch  3]: The total slot loss on train data is 71.615291, intent data is 177.795272, cost about 623.557 seconds.\n",
            "100%|███████████| 199/199 [01:49<00:00,  1.83it/s]\n",
            "100%|███████████| 199/199 [01:50<00:00,  1.81it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8854    0.7328    0.8019       348\n",
            "book_restaurant     0.7921    0.7543    0.7727       293\n",
            "     book_train     0.7797    0.7535    0.7664       357\n",
            "find_attraction     0.7930    0.9223    0.8528       914\n",
            "     find_hotel     0.8833    0.8363    0.8592       941\n",
            "    find_police     0.2500    0.5000    0.3333         2\n",
            "find_restaurant     0.8866    0.7430    0.8084       852\n",
            "      find_taxi     0.9660    0.8107    0.8816       280\n",
            "     find_train     0.9209    0.9472    0.9339      1230\n",
            "        general     0.8836    0.9884    0.9331      1121\n",
            "\n",
            "       accuracy                         0.8692      6338\n",
            "      macro avg     0.8041    0.7988    0.7943      6338\n",
            "   weighted avg     0.8716    0.8692    0.8675      6338\n",
            "\n",
            "Test result: slot f1 score: 0.884848, intent acc score: 0.869202, semantic accuracy score: 0.772168.\n",
            "epoch 3: 0.8692\n",
            "[Epoch  3]: In validation process, the slot f1 score is 0.885702, the intent acc is 0.871525, the semantic acc is 0.77, cost about 221.776558 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:53<00:00,  2.35it/s]\n",
            "[Epoch  4]: The total slot loss on train data is 65.478218, intent data is 198.421317, cost about 653.005 seconds.\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.83it/s]\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.83it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.9211    0.7040    0.7980       348\n",
            "book_restaurant     0.7611    0.7611    0.7611       293\n",
            "     book_train     0.8297    0.7507    0.7882       357\n",
            "find_attraction     0.8688    0.8479    0.8583       914\n",
            "     find_hotel     0.8818    0.8247    0.8523       941\n",
            "    find_police     0.1000    0.5000    0.1667         2\n",
            "find_restaurant     0.7847    0.8040    0.7942       852\n",
            "      find_taxi     0.9738    0.7964    0.8762       280\n",
            "     find_train     0.8990    0.9553    0.9263      1230\n",
            "        general     0.8767    0.9893    0.9296      1121\n",
            "\n",
            "       accuracy                         0.8646      6338\n",
            "      macro avg     0.7897    0.7933    0.7751      6338\n",
            "   weighted avg     0.8668    0.8646    0.8634      6338\n",
            "\n",
            "Test result: slot f1 score: 0.884316, intent acc score: 0.864626, semantic accuracy score: 0.772641.\n",
            "epoch 4: 0.8646\n",
            "[Epoch  4]: In validation process, the slot f1 score is 0.884848, the intent acc is 0.871054, the semantic acc is 0.78, cost about 219.857759 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:52<00:00,  2.35it/s]\n",
            "[Epoch  5]: The total slot loss on train data is 62.747511, intent data is 178.697146, cost about 652.108 seconds.\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.84it/s]\n",
            "100%|███████████| 199/199 [01:50<00:00,  1.81it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8662    0.7443    0.8006       348\n",
            "book_restaurant     0.8029    0.7509    0.7760       293\n",
            "     book_train     0.8196    0.7507    0.7836       357\n",
            "find_attraction     0.9214    0.7823    0.8462       914\n",
            "  find_hospital     0.0000    0.0000    0.0000         0\n",
            "     find_hotel     0.9051    0.8108    0.8554       941\n",
            "    find_police     0.2000    0.5000    0.2857         2\n",
            "find_restaurant     0.7165    0.8603    0.7819       852\n",
            "      find_taxi     0.9619    0.8107    0.8798       280\n",
            "     find_train     0.9038    0.9553    0.9289      1230\n",
            "        general     0.8851    0.9893    0.9343      1121\n",
            "\n",
            "       accuracy                         0.8630      6338\n",
            "      macro avg     0.7257    0.7231    0.7157      6338\n",
            "   weighted avg     0.8689    0.8630    0.8626      6338\n",
            "\n",
            "Test result: slot f1 score: 0.887203, intent acc score: 0.863048, semantic accuracy score: 0.769170.\n",
            "epoch 5: 0.863\n",
            "[Epoch  5]: In validation process, the slot f1 score is 0.886270, the intent acc is 0.873096, the semantic acc is 0.78, cost about 220.721051 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:27<00:00,  2.44it/s]\n",
            "[Epoch  6]: The total slot loss on train data is 58.079088, intent data is 165.218781, cost about 627.795 seconds.\n",
            "100%|███████████| 199/199 [01:49<00:00,  1.82it/s]\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.84it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.9245    0.7385    0.8211       348\n",
            "book_restaurant     0.7451    0.7782    0.7613       293\n",
            "     book_train     0.8454    0.7507    0.7953       357\n",
            "find_attraction     0.8864    0.8195    0.8516       914\n",
            "  find_hospital     0.0000    0.0000    0.0000         0\n",
            "     find_hotel     0.9068    0.8172    0.8597       941\n",
            "    find_police     0.2500    0.5000    0.3333         2\n",
            "find_restaurant     0.7428    0.8474    0.7917       852\n",
            "      find_taxi     0.9536    0.8071    0.8743       280\n",
            "     find_train     0.9099    0.9528    0.9309      1230\n",
            "        general     0.8896    0.9848    0.9348      1121\n",
            "\n",
            "       accuracy                         0.8672      6338\n",
            "      macro avg     0.7322    0.7269    0.7231      6338\n",
            "   weighted avg     0.8713    0.8672    0.8667      6338\n",
            "\n",
            "Test result: slot f1 score: 0.893166, intent acc score: 0.867151, semantic accuracy score: 0.778321.\n",
            "epoch 6: 0.8672\n",
            "[Epoch  6]: In validation process, the slot f1 score is 0.889151, the intent acc is 0.873724, the semantic acc is 0.78, cost about 219.591186 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:38<00:00,  2.40it/s]\n",
            "[Epoch  7]: The total slot loss on train data is 55.710302, intent data is 164.346510, cost about 638.401 seconds.\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.83it/s]\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.84it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8567    0.7557    0.8031       348\n",
            "book_restaurant     0.8421    0.7645    0.8014       293\n",
            "     book_train     0.8428    0.7507    0.7941       357\n",
            "find_attraction     0.8270    0.8993    0.8616       914\n",
            "  find_hospital     0.0000    0.0000    0.0000         0\n",
            "     find_hotel     0.8751    0.8268    0.8503       941\n",
            "    find_police     0.5000    0.5000    0.5000         2\n",
            "find_restaurant     0.8406    0.7923    0.8157       852\n",
            "      find_taxi     0.9661    0.8143    0.8837       280\n",
            "     find_train     0.9124    0.9480    0.9298      1230\n",
            "        general     0.8889    0.9848    0.9344      1121\n",
            "\n",
            "       accuracy                         0.8724      6338\n",
            "      macro avg     0.7592    0.7306    0.7431      6338\n",
            "   weighted avg     0.8727    0.8724    0.8709      6338\n",
            "\n",
            "Test result: slot f1 score: 0.893279, intent acc score: 0.872357, semantic accuracy score: 0.785106.\n",
            "epoch 7: 0.8724\n",
            "[Epoch  7]: In validation process, the slot f1 score is 0.890991, the intent acc is 0.880477, the semantic acc is 0.79, cost about 219.279243 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:41<00:00,  2.39it/s]\n",
            "[Epoch  8]: The total slot loss on train data is 55.325794, intent data is 175.135603, cost about 641.232 seconds.\n",
            "100%|███████████| 199/199 [01:49<00:00,  1.82it/s]\n",
            "100%|█████████| 1532/1532 [10:53<00:00,  2.34it/s]\n",
            "[Epoch  9]: The total slot loss on train data is 52.662108, intent data is 173.964518, cost about 653.371 seconds.\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.84it/s]\n",
            "100%|█████████| 1532/1532 [10:43<00:00,  2.38it/s]\n",
            "[Epoch 10]: The total slot loss on train data is 52.058053, intent data is 161.141812, cost about 643.15 seconds.\n",
            "100%|███████████| 199/199 [01:47<00:00,  1.85it/s]\n",
            "100%|█████████| 1532/1532 [10:27<00:00,  2.44it/s]\n",
            "[Epoch 11]: The total slot loss on train data is 50.863304, intent data is 148.766512, cost about 627.405 seconds.\n",
            "100%|███████████| 199/199 [01:48<00:00,  1.84it/s]\n",
            "100%|███████████| 199/199 [01:47<00:00,  1.85it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8920    0.7356    0.8063       348\n",
            "book_restaurant     0.8123    0.7679    0.7895       293\n",
            "     book_train     0.8471    0.7451    0.7928       357\n",
            "find_attraction     0.8524    0.8906    0.8711       914\n",
            "  find_hospital     0.0000    0.0000    0.0000         0\n",
            "     find_hotel     0.8925    0.8204    0.8549       941\n",
            "    find_police     0.1429    0.5000    0.2222         2\n",
            "find_restaurant     0.8259    0.8075    0.8166       852\n",
            "      find_taxi     0.9583    0.8214    0.8846       280\n",
            "     find_train     0.8990    0.9626    0.9297      1230\n",
            "        general     0.8918    0.9857    0.9364      1121\n",
            "\n",
            "       accuracy                         0.8743      6338\n",
            "      macro avg     0.7286    0.7306    0.7186      6338\n",
            "   weighted avg     0.8753    0.8743    0.8730      6338\n",
            "\n",
            "Test result: slot f1 score: 0.894203, intent acc score: 0.874251, semantic accuracy score: 0.787946.\n",
            "epoch 11: 0.8743\n",
            "[Epoch 11]: In validation process, the slot f1 score is 0.893342, the intent acc is 0.883462, the semantic acc is 0.79, cost about 218.476857 seconds.\n",
            "\n",
            "100%|█████████| 1532/1532 [10:32<00:00,  2.42it/s]\n",
            "[Epoch 12]: The total slot loss on train data is 49.537262, intent data is 142.991682, cost about 632.368 seconds.\n",
            " 22%|██▋         | 44/199 [00:23<01:19,  1.94it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP7uk63z7coq"
      },
      "source": [
        "# [A Co-Interactive Transformer for Joint Slot Filling and Intent Detection](https://github.com/kangbrilliant/DCA-Net)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ123bAzJjBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d080d91-178d-41d3-fc44-4570865e8810"
      },
      "source": [
        "# !git clone https://github.com/amiralikaboli/DCA-Net.git drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer > /dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADeMCfaZJvKF"
      },
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !cp drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets download thanakomsn/glove6b300dtxt > /dev/null\n",
        "# !unzip glove6b300dtxt.zip -d drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer/data > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJgzY0GQ6WFO"
      },
      "source": [
        "import json\n",
        "\n",
        "src_path = \"drive/MyDrive/Datasets/MultiWOZ_2.2_v2\"\n",
        "dst_path = \"drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer/data\"\n",
        "\n",
        "intent_label = \"intents\"\n",
        "slot_label = \"slots1\"\n",
        "\n",
        "\n",
        "vocab = [\"<pad>\", \"<unk>\", \"</s>\", \"</e>\"]\n",
        "with open(f\"{src_path}/words.json\", \"r\") as json_file:\n",
        "    vocab.extend(json.load(json_file))\n",
        "with open(f\"{dst_path}/vocab.txt\", \"w\") as txt_file:\n",
        "    txt_file.writelines([f\"{word}\\n\" for word in vocab])\n",
        "\n",
        "intents = [\"general\"]\n",
        "with open(f\"{src_path}/{intent_label}.json\", \"r\") as json_file:\n",
        "    intents.extend(json.load(json_file))\n",
        "with open(f\"{dst_path}/intent_label.txt\", \"w\") as txt_file:\n",
        "    txt_file.writelines([f\"{idx}\\t{intent}\\n\" for idx, intent in enumerate(intents)])\n",
        "\n",
        "slots = [\"<PAD>\", \"<start>\", \"<end>\"]\n",
        "with open(f\"{src_path}/{slot_label}.json\", \"r\") as json_file:\n",
        "    slots.extend(json.load(json_file))\n",
        "with open(f\"{dst_path}/slot_label.txt\", \"w\") as txt_file:\n",
        "    txt_file.writelines([f\"{idx}\\t{slot}\\n\" for idx, slot in enumerate(slots)])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr7PB6TwJ0UG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd03ab31-6f9f-4bff-a9e1-14dc7f49be93"
      },
      "source": [
        "!cd drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer && python main_joint.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   0% 0/20 [00:00<?, ?it/s][0.001]\n",
            "100% 1532/1532 [02:37<00:00,  9.73it/s]\n",
            "100% 199/199 [00:19<00:00, 10.20it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8790    0.9786    0.9261      1166\n",
            "           1     0.9402    0.6962    0.8000       339\n",
            "           2     0.8327    0.6869    0.7528       297\n",
            "           3     0.7487    0.8109    0.7785       349\n",
            "           4     0.8211    0.7123    0.7629       883\n",
            "           6     0.1000    0.5000    0.1667         2\n",
            "           7     0.9145    0.7409    0.8186       938\n",
            "           9     0.6198    0.8503    0.7170       882\n",
            "          10     0.9561    0.5976    0.7355       328\n",
            "          11     0.8770    0.9222    0.8991      1183\n",
            "\n",
            "    accuracy                         0.8208      6367\n",
            "   macro avg     0.7689    0.7496    0.7357      6367\n",
            "weighted avg     0.8376    0.8208    0.8207      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.543633 slot_loss: 1.239405 acc: 0.8208% slot f1: 0.7823 sent acc: 0.6485 \n",
            "\n",
            "Epoch:   5% 1/20 [02:58<56:30, 178.42s/it][0.001]\n",
            "100% 1532/1532 [02:37<00:00,  9.73it/s]\n",
            "100% 199/199 [00:19<00:00, 10.17it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9046    0.9760    0.9389      1166\n",
            "           1     0.8245    0.7345    0.7769       339\n",
            "           2     0.7778    0.7306    0.7535       297\n",
            "           3     0.8833    0.7593    0.8166       349\n",
            "           4     0.8889    0.6886    0.7760       883\n",
            "           6     0.5000    0.5000    0.5000         2\n",
            "           7     0.9298    0.7484    0.8293       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.6110    0.9172    0.7335       882\n",
            "          10     0.9004    0.6890    0.7807       328\n",
            "          11     0.8975    0.9180    0.9076      1183\n",
            "\n",
            "    accuracy                         0.8326      6367\n",
            "   macro avg     0.7380    0.6965    0.7103      6367\n",
            "weighted avg     0.8525    0.8326    0.8336      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.497456 slot_loss: 0.982999 acc: 0.8326% slot f1: 0.8041 sent acc: 0.6758 \n",
            "\n",
            "Epoch:  10% 2/20 [05:56<53:25, 178.11s/it][0.001]\n",
            "100% 1532/1532 [02:36<00:00,  9.78it/s]\n",
            "100% 199/199 [00:19<00:00, 10.28it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8837    0.9837    0.9310      1166\n",
            "           1     0.7196    0.8024    0.7587       339\n",
            "           2     0.8409    0.7475    0.7914       297\n",
            "           3     0.8548    0.7593    0.8042       349\n",
            "           4     0.7098    0.9060    0.7960       883\n",
            "           6     0.5000    0.5000    0.5000         2\n",
            "           7     0.9184    0.7441    0.8221       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.8436    0.7154    0.7742       882\n",
            "          10     0.8911    0.6738    0.7674       328\n",
            "          11     0.8972    0.9146    0.9058      1183\n",
            "\n",
            "    accuracy                         0.8385      6367\n",
            "   macro avg     0.7327    0.7043    0.7137      6367\n",
            "weighted avg     0.8496    0.8385    0.8387      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.498602 slot_loss: 0.902417 acc: 0.8385% slot f1: 0.8142 sent acc: 0.7022 \n",
            "\n",
            "Epoch:  15% 3/20 [08:53<50:18, 177.56s/it][0.001]\n",
            "100% 1532/1532 [02:36<00:00,  9.82it/s]\n",
            "100% 199/199 [00:19<00:00, 10.23it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8990    0.9768    0.9363      1166\n",
            "           1     0.8972    0.7463    0.8148       339\n",
            "           2     0.7986    0.7475    0.7722       297\n",
            "           3     0.7830    0.8166    0.7994       349\n",
            "           4     0.7866    0.8392    0.8121       883\n",
            "           6     0.5000    0.5000    0.5000         2\n",
            "           7     0.9368    0.7591    0.8386       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7396    0.8084    0.7725       882\n",
            "          10     0.8107    0.7835    0.7969       328\n",
            "          11     0.9102    0.8994    0.9048      1183\n",
            "\n",
            "    accuracy                         0.8461      6367\n",
            "   macro avg     0.7329    0.7161    0.7225      6367\n",
            "weighted avg     0.8532    0.8461    0.8472      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.470752 slot_loss: 0.832167 acc: 0.8461% slot f1: 0.8221 sent acc: 0.6995 \n",
            "\n",
            "Epoch:  20% 4/20 [11:49<47:12, 177.00s/it][0.001]\n",
            "100% 1532/1532 [02:36<00:00,  9.82it/s]\n",
            "100% 199/199 [00:19<00:00, 10.29it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9102    0.9734    0.9407      1166\n",
            "           1     0.8877    0.7463    0.8109       339\n",
            "           2     0.8816    0.7273    0.7970       297\n",
            "           3     0.8132    0.8109    0.8121       349\n",
            "           4     0.7502    0.8947    0.8161       883\n",
            "           6     0.3333    0.5000    0.4000         2\n",
            "           7     0.9535    0.7431    0.8352       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7800    0.7676    0.7737       882\n",
            "          10     0.9727    0.6524    0.7810       328\n",
            "          11     0.8447    0.9611    0.8992      1183\n",
            "\n",
            "    accuracy                         0.8486      6367\n",
            "   macro avg     0.7388    0.7070    0.7151      6367\n",
            "weighted avg     0.8594    0.8486    0.8480      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.473863 slot_loss: 0.817341 acc: 0.8486% slot f1: 0.8240 sent acc: 0.7156 \n",
            "\n",
            "Epoch:  25% 5/20 [14:45<44:11, 176.75s/it][0.001]\n",
            "100% 1532/1532 [02:36<00:00,  9.81it/s]\n",
            "100% 199/199 [00:19<00:00, 10.19it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8863    0.9828    0.9321      1166\n",
            "           1     0.8349    0.7758    0.8043       339\n",
            "           2     0.8536    0.6869    0.7612       297\n",
            "           3     0.8762    0.7708    0.8201       349\n",
            "           4     0.7935    0.8528    0.8221       883\n",
            "           6     0.5000    0.5000    0.5000         2\n",
            "           7     0.8803    0.7996    0.8380       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7917    0.7585    0.7748       882\n",
            "          10     0.9561    0.6646    0.7842       328\n",
            "          11     0.8463    0.9544    0.8971      1183\n",
            "\n",
            "    accuracy                         0.8484      6367\n",
            "   macro avg     0.7472    0.7042    0.7213      6367\n",
            "weighted avg     0.8507    0.8484    0.8460      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.470508 slot_loss: 0.807899 acc: 0.8484% slot f1: 0.8228 sent acc: 0.7159 \n",
            "\n",
            "Epoch:  30% 6/20 [17:41<41:11, 176.51s/it][0.001]\n",
            "100% 1532/1532 [02:37<00:00,  9.70it/s]\n",
            "100% 199/199 [00:19<00:00, 10.38it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8791    0.9854    0.9292      1166\n",
            "           1     0.9294    0.7375    0.8224       339\n",
            "           2     0.8703    0.7003    0.7761       297\n",
            "           3     0.7799    0.8023    0.7910       349\n",
            "           4     0.7716    0.8800    0.8222       883\n",
            "           6     0.3333    0.5000    0.4000         2\n",
            "           7     0.9152    0.7591    0.8298       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7789    0.7789    0.7789       882\n",
            "          10     0.9383    0.6951    0.7986       328\n",
            "          11     0.8771    0.9467    0.9106      1183\n",
            "\n",
            "    accuracy                         0.8500      6367\n",
            "   macro avg     0.7339    0.7078    0.7144      6367\n",
            "weighted avg     0.8550    0.8500    0.8482      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.455183 slot_loss: 0.780612 acc: 0.8500% slot f1: 0.8257 sent acc: 0.7187 \n",
            "\n",
            "Epoch:  35% 7/20 [20:39<38:20, 176.98s/it][0.001]\n",
            "100% 1532/1532 [02:35<00:00,  9.86it/s]\n",
            "100% 199/199 [00:19<00:00, 10.24it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8938    0.9820    0.9358      1166\n",
            "           1     0.9110    0.7552    0.8258       339\n",
            "           2     0.7941    0.8182    0.8060       297\n",
            "           3     0.8550    0.8109    0.8324       349\n",
            "           4     0.7586    0.8969    0.8220       883\n",
            "           6     0.3333    1.0000    0.5000         2\n",
            "           7     0.8797    0.7793    0.8265       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.8176    0.7676    0.7918       882\n",
            "          10     0.9231    0.6951    0.7930       328\n",
            "          11     0.9024    0.9222    0.9122      1183\n",
            "\n",
            "    accuracy                         0.8557      6367\n",
            "   macro avg     0.7335    0.7661    0.7314      6367\n",
            "weighted avg     0.8595    0.8557    0.8545      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.451652 slot_loss: 0.757066 acc: 0.8557% slot f1: 0.8272 sent acc: 0.7214 \n",
            "\n",
            "Epoch:  40% 8/20 [23:35<35:18, 176.56s/it][0.001]\n",
            "100% 1532/1532 [02:36<00:00,  9.81it/s]\n",
            "100% 199/199 [00:19<00:00, 10.12it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8965    0.9803    0.9365      1166\n",
            "           1     0.9179    0.7581    0.8304       339\n",
            "           2     0.7974    0.8350    0.8158       297\n",
            "           3     0.8506    0.7994    0.8242       349\n",
            "           4     0.7671    0.8652    0.8132       883\n",
            "           6     0.0323    0.5000    0.0606         2\n",
            "           7     0.8904    0.7708    0.8263       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.8107    0.7574    0.7831       882\n",
            "          10     0.9268    0.6951    0.7944       328\n",
            "          11     0.8820    0.9417    0.9109      1183\n",
            "\n",
            "    accuracy                         0.8520      6367\n",
            "   macro avg     0.7065    0.7185    0.6905      6367\n",
            "weighted avg     0.8584    0.8520    0.8521      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.461346 slot_loss: 0.758641 acc: 0.8520% slot f1: 0.8268 sent acc: 0.7184 \n",
            "\n",
            "Epoch:  45% 9/20 [26:31<32:20, 176.40s/it][0.001]\n",
            "100% 1532/1532 [02:37<00:00,  9.74it/s]\n",
            "100% 199/199 [00:19<00:00, 10.13it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8851    0.9846    0.9322      1166\n",
            "           1     0.8908    0.7463    0.8122       339\n",
            "           2     0.8902    0.7374    0.8066       297\n",
            "           3     0.8017    0.7880    0.7948       349\n",
            "           4     0.8101    0.8505    0.8298       883\n",
            "           6     0.1667    0.5000    0.2500         2\n",
            "           7     0.9116    0.7804    0.8409       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7646    0.8027    0.7832       882\n",
            "          10     0.9609    0.6738    0.7921       328\n",
            "          11     0.8649    0.9527    0.9067      1183\n",
            "\n",
            "    accuracy                         0.8536      6367\n",
            "   macro avg     0.7224    0.7106    0.7044      6367\n",
            "weighted avg     0.8578    0.8536    0.8520      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.456709 slot_loss: 0.754903 acc: 0.8536% slot f1: 0.8323 sent acc: 0.7253 \n",
            "\n",
            "Epoch:  50% 10/20 [29:28<29:27, 176.78s/it][0.001]\n",
            "100% 1532/1532 [02:36<00:00,  9.82it/s]\n",
            "100% 199/199 [00:19<00:00, 10.17it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8951    0.9811    0.9362      1166\n",
            "           1     0.9466    0.7316    0.8253       339\n",
            "           2     0.7047    0.8519    0.7713       297\n",
            "           3     0.8983    0.7593    0.8230       349\n",
            "           4     0.8084    0.8743    0.8400       883\n",
            "           6     0.1429    0.5000    0.2222         2\n",
            "           7     0.8995    0.7921    0.8424       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.8183    0.7710    0.7939       882\n",
            "          10     0.9574    0.6860    0.7993       328\n",
            "          11     0.8612    0.9544    0.9054      1183\n",
            "\n",
            "    accuracy                         0.8575      6367\n",
            "   macro avg     0.7211    0.7183    0.7054      6367\n",
            "weighted avg     0.8638    0.8575    0.8565      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.454865 slot_loss: 0.755829 acc: 0.8575% slot f1: 0.8294 sent acc: 0.7302 \n",
            "\n",
            "Epoch:  55% 11/20 [32:25<26:29, 176.63s/it][0.001]\n",
            "100% 1532/1532 [02:37<00:00,  9.71it/s]\n",
            "100% 199/199 [00:19<00:00, 10.07it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9079    0.9726    0.9391      1166\n",
            "           1     0.8982    0.7552    0.8205       339\n",
            "           2     0.8179    0.8013    0.8095       297\n",
            "           3     0.8158    0.7994    0.8075       349\n",
            "           4     0.8273    0.8086    0.8179       883\n",
            "           6     0.2000    0.5000    0.2857         2\n",
            "           7     0.8416    0.7985    0.8195       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7636    0.8095    0.7859       882\n",
            "          10     0.8856    0.7317    0.8013       328\n",
            "          11     0.8913    0.9290    0.9098      1183\n",
            "\n",
            "    accuracy                         0.8519      6367\n",
            "   macro avg     0.7136    0.7187    0.7088      6367\n",
            "weighted avg     0.8528    0.8519    0.8511      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.436334 slot_loss: 0.732971 acc: 0.8519% slot f1: 0.8287 sent acc: 0.7174 \n",
            "\n",
            "Epoch:  60% 12/20 [35:23<23:35, 176.98s/it][0.001]\n",
            "100% 1532/1532 [02:36<00:00,  9.81it/s]\n",
            "100% 199/199 [00:19<00:00, 10.07it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9111    0.9674    0.9384      1166\n",
            "           1     0.8307    0.7817    0.8055       339\n",
            "           2     0.8821    0.7811    0.8286       297\n",
            "           3     0.8109    0.8109    0.8109       349\n",
            "           4     0.7718    0.8732    0.8193       883\n",
            "           6     0.0667    0.5000    0.1176         2\n",
            "           7     0.8475    0.8060    0.8262       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.8284    0.7664    0.7962       882\n",
            "          10     0.9046    0.7226    0.8034       328\n",
            "          11     0.8993    0.9214    0.9102      1183\n",
            "\n",
            "    accuracy                         0.8542      6367\n",
            "   macro avg     0.7048    0.7210    0.6960      6367\n",
            "weighted avg     0.8571    0.8542    0.8540      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.456303 slot_loss: 0.712408 acc: 0.8542% slot f1: 0.8328 sent acc: 0.7255 \n",
            "\n",
            "Epoch:  65% 13/20 [38:19<20:37, 176.79s/it][0.001]\n",
            "100% 1532/1532 [02:39<00:00,  9.62it/s]\n",
            "100% 199/199 [00:19<00:00, 10.27it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8917    0.9811    0.9343      1166\n",
            "           1     0.9209    0.7552    0.8298       339\n",
            "           2     0.8084    0.7811    0.7945       297\n",
            "           3     0.8494    0.8080    0.8282       349\n",
            "           4     0.8142    0.8437    0.8287       883\n",
            "           6     0.0556    0.5000    0.1000         2\n",
            "           7     0.8710    0.8134    0.8412       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7912    0.7732    0.7821       882\n",
            "          10     0.9339    0.6890    0.7930       328\n",
            "          11     0.8814    0.9484    0.9137      1183\n",
            "\n",
            "    accuracy                         0.8564      6367\n",
            "   macro avg     0.7107    0.7176    0.6950      6367\n",
            "weighted avg     0.8593    0.8564    0.8556      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.442908 slot_loss: 0.762637 acc: 0.8564% slot f1: 0.8312 sent acc: 0.7291 \n",
            "\n",
            "Epoch:  70% 14/20 [41:18<17:44, 177.40s/it][0.001]\n",
            "100% 1532/1532 [02:38<00:00,  9.66it/s]\n",
            "100% 199/199 [00:20<00:00,  9.94it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8932    0.9828    0.9359      1166\n",
            "           1     0.8557    0.7522    0.8006       339\n",
            "           2     0.8717    0.7778    0.8221       297\n",
            "           3     0.8541    0.8052    0.8289       349\n",
            "           4     0.8370    0.8199    0.8284       883\n",
            "           6     0.1429    0.5000    0.2222         2\n",
            "           7     0.7962    0.8124    0.8042       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7778    0.7857    0.7817       882\n",
            "          10     0.9141    0.7134    0.8014       328\n",
            "          11     0.9059    0.9273    0.9165      1183\n",
            "\n",
            "    accuracy                         0.8519      6367\n",
            "   macro avg     0.7135    0.7161    0.7038      6367\n",
            "weighted avg     0.8532    0.8519    0.8511      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.448856 slot_loss: 0.735265 acc: 0.8519% slot f1: 0.8285 sent acc: 0.7223 \n",
            "\n",
            "Epoch:  75% 15/20 [44:17<14:49, 177.86s/it][0.001]\n",
            "100% 1532/1532 [02:38<00:00,  9.68it/s]\n",
            "100% 199/199 [00:19<00:00, 10.09it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8895    0.9803    0.9327      1166\n",
            "           1     0.8690    0.7434    0.8013       339\n",
            "           2     0.7973    0.7811    0.7891       297\n",
            "           3     0.8766    0.7937    0.8331       349\n",
            "           4     0.8272    0.8131    0.8201       883\n",
            "           6     0.0556    0.5000    0.1000         2\n",
            "           7     0.8113    0.8294    0.8202       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7991    0.7664    0.7824       882\n",
            "          10     0.9262    0.6890    0.7902       328\n",
            "          11     0.8921    0.9366    0.9138      1183\n",
            "\n",
            "    accuracy                         0.8499      6367\n",
            "   macro avg     0.7040    0.7121    0.6894      6367\n",
            "weighted avg     0.8528    0.8499    0.8494      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.452401 slot_loss: 0.704880 acc: 0.8499% slot f1: 0.8328 sent acc: 0.7299 \n",
            "\n",
            "Epoch:  80% 16/20 [47:15<11:51, 177.97s/it][0.001]\n",
            "100% 1532/1532 [02:38<00:00,  9.65it/s]\n",
            "100% 199/199 [00:19<00:00, 10.07it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9025    0.9760    0.9378      1166\n",
            "           1     0.9084    0.7316    0.8105       339\n",
            "           2     0.8609    0.7710    0.8135       297\n",
            "           3     0.8187    0.8023    0.8104       349\n",
            "           4     0.8223    0.8279    0.8251       883\n",
            "           6     0.1000    0.5000    0.1667         2\n",
            "           7     0.8077    0.8550    0.8307       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.8344    0.7370    0.7827       882\n",
            "          10     0.9315    0.7043    0.8021       328\n",
            "          11     0.8637    0.9484    0.9041      1183\n",
            "\n",
            "    accuracy                         0.8531      6367\n",
            "   macro avg     0.7136    0.7139    0.6985      6367\n",
            "weighted avg     0.8558    0.8531    0.8518      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.453494 slot_loss: 0.705102 acc: 0.8531% slot f1: 0.8322 sent acc: 0.7275 \n",
            "\n",
            "Epoch:  85% 17/20 [50:14<08:54, 178.22s/it][0.001]\n",
            "100% 1532/1532 [02:39<00:00,  9.61it/s]\n",
            "100% 199/199 [00:19<00:00, 10.01it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9033    0.9777    0.9390      1166\n",
            "           1     0.7930    0.8024    0.7977       339\n",
            "           2     0.8808    0.7710    0.8223       297\n",
            "           3     0.8536    0.7851    0.8179       349\n",
            "           4     0.7960    0.8664    0.8297       883\n",
            "           6     0.1250    0.5000    0.2000         2\n",
            "           7     0.7960    0.8443    0.8195       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.8650    0.7268    0.7899       882\n",
            "          10     0.9317    0.7073    0.8042       328\n",
            "          11     0.8987    0.9298    0.9140      1183\n",
            "\n",
            "    accuracy                         0.8553      6367\n",
            "   macro avg     0.7130    0.7192    0.7031      6367\n",
            "weighted avg     0.8580    0.8553    0.8542      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.453939 slot_loss: 0.714117 acc: 0.8553% slot f1: 0.8342 sent acc: 0.7322 \n",
            "\n",
            "Epoch:  90% 18/20 [53:14<05:57, 178.73s/it][0.001]\n",
            "100% 1532/1532 [02:38<00:00,  9.64it/s]\n",
            "100% 199/199 [00:20<00:00,  9.94it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9017    0.9751    0.9370      1166\n",
            "           1     0.8854    0.7522    0.8134       339\n",
            "           2     0.7878    0.8249    0.8059       297\n",
            "           3     0.8528    0.7966    0.8237       349\n",
            "           4     0.7526    0.8992    0.8194       883\n",
            "           6     0.0455    0.5000    0.0833         2\n",
            "           7     0.8655    0.7751    0.8178       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.8444    0.7324    0.7845       882\n",
            "          10     0.9289    0.7165    0.8090       328\n",
            "          11     0.8961    0.9400    0.9175      1183\n",
            "\n",
            "    accuracy                         0.8528      6367\n",
            "   macro avg     0.7055    0.7193    0.6919      6367\n",
            "weighted avg     0.8590    0.8528    0.8526      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.451595 slot_loss: 0.735282 acc: 0.8528% slot f1: 0.8327 sent acc: 0.7259 \n",
            "\n",
            "Epoch:  95% 19/20 [56:13<02:58, 178.87s/it][0.001]\n",
            "100% 1532/1532 [02:40<00:00,  9.54it/s]\n",
            "100% 199/199 [00:19<00:00,  9.98it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8965    0.9803    0.9365      1166\n",
            "           1     0.9113    0.7581    0.8277       339\n",
            "           2     0.8182    0.7879    0.8027       297\n",
            "           3     0.8615    0.8023    0.8309       349\n",
            "           4     0.8380    0.8086    0.8231       883\n",
            "           6     0.0556    0.5000    0.1000         2\n",
            "           7     0.8099    0.8220    0.8159       938\n",
            "           8     0.0000    0.0000    0.0000         0\n",
            "           9     0.7901    0.7766    0.7833       882\n",
            "          10     0.9062    0.7073    0.7945       328\n",
            "          11     0.8909    0.9391    0.9144      1183\n",
            "\n",
            "    accuracy                         0.8525      6367\n",
            "   macro avg     0.7071    0.7166    0.6935      6367\n",
            "weighted avg     0.8553    0.8525    0.8523      6367\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.446624 slot_loss: 0.718558 acc: 0.8525% slot f1: 0.8292 sent acc: 0.7233 \n",
            "\n",
            "Epoch: 100% 20/20 [59:14<00:00, 177.70s/it]\n",
            "best_slot_f1: [0.7322129731427673, 0.8342319212665811, 0.8553478875451547, 17]\n",
            "best_intent_acc: [0.7301711952253809, 0.829350387075059, 0.8575467253023402, 10]\n",
            "best_sent_acc: [0.7322129731427673, 0.8342319212665811, 0.8553478875451547, 17]\n",
            "100% 199/199 [00:15<00:00, 12.63it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8908    0.9822    0.9342      1121\n",
            "           1     0.7988    0.7874    0.7931       348\n",
            "           2     0.8240    0.7031    0.7587       293\n",
            "           3     0.8667    0.7283    0.7915       357\n",
            "           4     0.8172    0.8753    0.8452       914\n",
            "           6     0.0000    0.0000    0.0000         0\n",
            "           7     0.8070    0.8353    0.8209       941\n",
            "           8     0.2500    0.5000    0.3333         2\n",
            "           9     0.8282    0.7300    0.7760       852\n",
            "          10     0.9731    0.7750    0.8628       280\n",
            "          11     0.9082    0.9415    0.9246      1230\n",
            "\n",
            "    accuracy                         0.8559      6338\n",
            "   macro avg     0.7240    0.7144    0.7128      6338\n",
            "weighted avg     0.8566    0.8559    0.8542      6338\n",
            "\n",
            "\n",
            "Evaluation -  acc: 0.8559% slot f1: 0.8391 sent_acc: 0.7280  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOH3matWFggx"
      },
      "source": [
        "# [A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling](https://github.com/ray075hl/Bi-Model-Intent-And-Slot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d1fdudSKN4h"
      },
      "source": [
        "# !git clone https://github.com/amiralikaboli/Bi-Model-Intent-And-Slot.git drive/MyDrive/Dev/ID_in_CRS/Bi-Model-Intent-And-Slot  > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgKSPtKeKX9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe4d56d-3f0d-4717-ee75-c189dfb1e2f6"
      },
      "source": [
        "!cd drive/MyDrive/Dev/ID_in_CRS/Bi-Model-Intent-And-Slot && python train_args.py -te 20 -bb 32 -es 50 -lhs 192"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  48779\n",
            "Number of test samples:  6298\n",
            "Number of words:  1959\n",
            "Number of intent labels:  11\n",
            "Number of slot labels 60\n",
            "##################################################\n",
            "{'book_hotel': 0, 'book_restaurant': 1, 'book_train': 2, 'find_attraction': 3, 'find_hospital': 4, 'find_hotel': 5, 'find_police': 6, 'find_restaurant': 7, 'find_taxi': 8, 'find_train': 9, 'general': 10}\n",
            "1524it [10:48,  2.35it/s]\n",
            "196it [00:28,  6.93it/s]\n",
            "Epoch: [1/20], Intent Val Acc: 84.71 \t Slot F1 score: 83.81\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8274    0.7405    0.7815       343\n",
            "           1     0.8621    0.6873    0.7648       291\n",
            "           2     0.7805    0.7211    0.7496       355\n",
            "           3     0.8369    0.8248    0.8308       902\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.7904    0.8491    0.8187       928\n",
            "           6     0.0000    0.0000    0.0000         2\n",
            "           7     0.8078    0.7628    0.7846       843\n",
            "           8     1.0000    0.6606    0.7957       277\n",
            "           9     0.8791    0.9522    0.9142      1214\n",
            "          10     0.8919    0.9749    0.9316      1117\n",
            "\n",
            "    accuracy                         0.8471      6272\n",
            "   macro avg     0.6978    0.6521    0.6701      6272\n",
            "weighted avg     0.8485    0.8471    0.8447      6272\n",
            "\n",
            "Best Intent Acc: 84.71 at Epoch: [1]\n",
            "Best F1 score: 83.81 at Epoch: [1]\n",
            "**************************************************\n",
            "1524it [10:48,  2.35it/s]\n",
            "196it [00:28,  6.94it/s]\n",
            "Epoch: [2/20], Intent Val Acc: 85.59 \t Slot F1 score: 85.87\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8489    0.7719    0.8086       342\n",
            "           1     0.8477    0.7055    0.7701       292\n",
            "           2     0.8043    0.7358    0.7685       352\n",
            "           3     0.8468    0.8374    0.8420       904\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8178    0.8434    0.8304       926\n",
            "           6     0.2500    0.5000    0.3333         2\n",
            "           7     0.7854    0.7509    0.7677       843\n",
            "           8     0.9256    0.8087    0.8632       277\n",
            "           9     0.9005    0.9426    0.9210      1219\n",
            "          10     0.8989    0.9812    0.9383      1115\n",
            "\n",
            "    accuracy                         0.8559      6272\n",
            "   macro avg     0.7205    0.7161    0.7130      6272\n",
            "weighted avg     0.8550    0.8559    0.8543      6272\n",
            "\n",
            "Best Intent Acc: 85.59 at Epoch: [2]\n",
            "Best F1 score: 85.87 at Epoch: [2]\n",
            "**************************************************\n",
            "1524it [10:49,  2.35it/s]\n",
            "196it [00:28,  6.91it/s]\n",
            "Epoch: [3/20], Intent Val Acc: 85.83 \t Slot F1 score: 86.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8901    0.7168    0.7941       339\n",
            "           1     0.8061    0.7260    0.7640       292\n",
            "           2     0.8323    0.7429    0.7851       354\n",
            "           3     0.8331    0.8211    0.8271       900\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.9243    0.7750    0.8431       929\n",
            "           6     0.3333    0.5000    0.4000         2\n",
            "           7     0.7143    0.8600    0.7804       843\n",
            "           8     0.9426    0.8303    0.8829       277\n",
            "           9     0.9188    0.9475    0.9329      1218\n",
            "          10     0.8882    0.9803    0.9320      1118\n",
            "\n",
            "    accuracy                         0.8583      6272\n",
            "   macro avg     0.7348    0.7182    0.7220      6272\n",
            "weighted avg     0.8636    0.8583    0.8577      6272\n",
            "\n",
            "Best Intent Acc: 85.83 at Epoch: [3]\n",
            "Best F1 score: 86.95 at Epoch: [3]\n",
            "**************************************************\n",
            "1524it [10:49,  2.35it/s]\n",
            "196it [00:28,  6.94it/s]\n",
            "Epoch: [4/20], Intent Val Acc: 86.22 \t Slot F1 score: 86.73\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8168    0.7977    0.8071       341\n",
            "           1     0.8908    0.7010    0.7846       291\n",
            "           2     0.8557    0.7373    0.7921       354\n",
            "           3     0.8673    0.8250    0.8456       903\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8101    0.8477    0.8285       926\n",
            "           6     0.2000    0.5000    0.2857         2\n",
            "           7     0.7922    0.7969    0.7946       842\n",
            "           8     0.9524    0.7942    0.8661       277\n",
            "           9     0.9165    0.9450    0.9305      1219\n",
            "          10     0.8926    0.9821    0.9352      1117\n",
            "\n",
            "    accuracy                         0.8622      6272\n",
            "   macro avg     0.7268    0.7206    0.7155      6272\n",
            "weighted avg     0.8641    0.8622    0.8615      6272\n",
            "\n",
            "Best Intent Acc: 86.22 at Epoch: [4]\n",
            "Best F1 score: 86.95 at Epoch: [3]\n",
            "**************************************************\n",
            "1524it [10:48,  2.35it/s]\n",
            "196it [00:28,  6.98it/s]\n",
            "Epoch: [5/20], Intent Val Acc: 86.21 \t Slot F1 score: 87.53\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8308    0.7849    0.8072       344\n",
            "           1     0.8014    0.7629    0.7817       291\n",
            "           2     0.8673    0.7203    0.7870       354\n",
            "           3     0.8455    0.8370    0.8412       902\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8726    0.8247    0.8480       930\n",
            "           6     0.1111    0.5000    0.1818         2\n",
            "           7     0.7721    0.7867    0.7793       844\n",
            "           8     0.9489    0.8080    0.8728       276\n",
            "           9     0.9070    0.9524    0.9291      1218\n",
            "          10     0.8964    0.9811    0.9368      1111\n",
            "\n",
            "    accuracy                         0.8621      6272\n",
            "   macro avg     0.7139    0.7235    0.7059      6272\n",
            "weighted avg     0.8633    0.8621    0.8614      6272\n",
            "\n",
            "Best Intent Acc: 86.22 at Epoch: [4]\n",
            "Best F1 score: 87.53 at Epoch: [5]\n",
            "**************************************************\n",
            "1524it [10:50,  2.34it/s]\n",
            "196it [00:28,  6.92it/s]\n",
            "Epoch: [6/20], Intent Val Acc: 86.94 \t Slot F1 score: 87.40\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8567    0.7843    0.8189       343\n",
            "           1     0.7893    0.7674    0.7782       288\n",
            "           2     0.8836    0.7288    0.7988       354\n",
            "           3     0.8462    0.8808    0.8632       906\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8246    0.8504    0.8373       929\n",
            "           6     0.5000    0.5000    0.5000         2\n",
            "           7     0.8501    0.7595    0.8023       844\n",
            "           8     0.9700    0.8188    0.8880       276\n",
            "           9     0.9102    0.9530    0.9311      1213\n",
            "          10     0.8937    0.9785    0.9342      1117\n",
            "\n",
            "    accuracy                         0.8694      6272\n",
            "   macro avg     0.7568    0.7292    0.7411      6272\n",
            "weighted avg     0.8698    0.8694    0.8680      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.53 at Epoch: [5]\n",
            "**************************************************\n",
            "1524it [10:47,  2.35it/s]\n",
            "196it [00:28,  6.95it/s]\n",
            "Epoch: [7/20], Intent Val Acc: 86.61 \t Slot F1 score: 87.15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7959    0.8029    0.7994       340\n",
            "           1     0.8308    0.7397    0.7826       292\n",
            "           2     0.8938    0.7394    0.8093       353\n",
            "           3     0.8468    0.8664    0.8565       906\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8553    0.8414    0.8483       927\n",
            "           6     0.1000    0.5000    0.1667         2\n",
            "           7     0.8289    0.7790    0.8032       846\n",
            "           8     0.8980    0.8327    0.8642       275\n",
            "           9     0.9303    0.9326    0.9314      1216\n",
            "          10     0.8902    0.9812    0.9334      1115\n",
            "\n",
            "    accuracy                         0.8661      6272\n",
            "   macro avg     0.7155    0.7287    0.7086      6272\n",
            "weighted avg     0.8707    0.8661    0.8672      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.53 at Epoch: [5]\n",
            "**************************************************\n",
            "1524it [10:40,  2.38it/s]\n",
            "196it [00:27,  7.04it/s]\n",
            "Epoch: [8/20], Intent Val Acc: 86.56 \t Slot F1 score: 87.43\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8938    0.7676    0.8259       340\n",
            "           1     0.7568    0.7595    0.7581       291\n",
            "           2     0.9059    0.7365    0.8125       353\n",
            "           3     0.8486    0.8608    0.8546       905\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8272    0.8495    0.8382       930\n",
            "           6     0.1250    0.5000    0.2000         2\n",
            "           7     0.8312    0.7669    0.7978       841\n",
            "           8     0.9224    0.8159    0.8659       277\n",
            "           9     0.9057    0.9548    0.9296      1217\n",
            "          10     0.9018    0.9713    0.9353      1116\n",
            "\n",
            "    accuracy                         0.8656      6272\n",
            "   macro avg     0.7199    0.7257    0.7107      6272\n",
            "weighted avg     0.8681    0.8656    0.8654      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.53 at Epoch: [5]\n",
            "**************************************************\n",
            "1524it [10:39,  2.38it/s]\n",
            "196it [00:27,  7.05it/s]\n",
            "Epoch: [9/20], Intent Val Acc: 86.48 \t Slot F1 score: 87.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8447    0.7587    0.7994       344\n",
            "           1     0.7516    0.8007    0.7754       291\n",
            "           2     0.8733    0.7203    0.7895       354\n",
            "           3     0.8485    0.8456    0.8470       907\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8611    0.8332    0.8469       923\n",
            "           6     0.0833    0.5000    0.1429         2\n",
            "           7     0.7955    0.8031    0.7993       843\n",
            "           8     0.9456    0.8218    0.8794       275\n",
            "           9     0.9285    0.9368    0.9326      1219\n",
            "          10     0.8915    0.9811    0.9342      1114\n",
            "\n",
            "    accuracy                         0.8648      6272\n",
            "   macro avg     0.7112    0.7274    0.7042      6272\n",
            "weighted avg     0.8671    0.8648    0.8647      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:46,  2.36it/s]\n",
            "196it [00:28,  6.85it/s]\n",
            "Epoch: [10/20], Intent Val Acc: 86.40 \t Slot F1 score: 87.32\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8471    0.7755    0.8097       343\n",
            "           1     0.7426    0.7732    0.7576       291\n",
            "           2     0.9151    0.7025    0.7949       353\n",
            "           3     0.8757    0.8359    0.8554       902\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8405    0.8378    0.8392       931\n",
            "           6     0.1429    0.5000    0.2222         2\n",
            "           7     0.8014    0.7882    0.7947       845\n",
            "           8     0.9824    0.8051    0.8849       277\n",
            "           9     0.9005    0.9605    0.9295      1215\n",
            "          10     0.8912    0.9784    0.9328      1113\n",
            "\n",
            "    accuracy                         0.8640      6272\n",
            "   macro avg     0.7218    0.7234    0.7110      6272\n",
            "weighted avg     0.8670    0.8640    0.8636      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:47,  2.35it/s]\n",
            "196it [00:28,  6.90it/s]\n",
            "Epoch: [11/20], Intent Val Acc: 86.07 \t Slot F1 score: 87.41\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8885    0.7413    0.8082       344\n",
            "           1     0.7551    0.7655    0.7603       290\n",
            "           2     0.8344    0.7585    0.7946       352\n",
            "           3     0.8807    0.8077    0.8427       905\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8464    0.8373    0.8418       928\n",
            "           6     0.1250    0.5000    0.2000         2\n",
            "           7     0.7572    0.8167    0.7858       840\n",
            "           8     0.9091    0.8303    0.8679       277\n",
            "           9     0.9293    0.9286    0.9290      1218\n",
            "          10     0.8920    0.9839    0.9357      1116\n",
            "\n",
            "    accuracy                         0.8607      6272\n",
            "   macro avg     0.7107    0.7245    0.7060      6272\n",
            "weighted avg     0.8636    0.8607    0.8607      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:47,  2.35it/s]\n",
            "196it [00:28,  6.87it/s]\n",
            "Epoch: [12/20], Intent Val Acc: 86.64 \t Slot F1 score: 87.72\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8709    0.7668    0.8155       343\n",
            "           1     0.7081    0.7808    0.7427       292\n",
            "           2     0.9247    0.7309    0.8165       353\n",
            "           3     0.8707    0.8331    0.8515       905\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8736    0.8207    0.8463       926\n",
            "           6     0.0500    0.5000    0.0909         2\n",
            "           7     0.7789    0.8233    0.8005       843\n",
            "           8     0.9190    0.8225    0.8681       276\n",
            "           9     0.9260    0.9458    0.9358      1218\n",
            "          10     0.8970    0.9847    0.9388      1114\n",
            "\n",
            "    accuracy                         0.8664      6272\n",
            "   macro avg     0.7108    0.7281    0.7006      6272\n",
            "weighted avg     0.8715    0.8664    0.8672      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:47,  2.35it/s]\n",
            "196it [00:27,  7.01it/s]\n",
            "Epoch: [13/20], Intent Val Acc: 86.65 \t Slot F1 score: 87.41\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7994    0.7924    0.7959       342\n",
            "           1     0.7706    0.7363    0.7531       292\n",
            "           2     0.8851    0.7401    0.8062       354\n",
            "           3     0.8374    0.8642    0.8506       906\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8573    0.8369    0.8470       926\n",
            "           6     0.3333    0.5000    0.4000         2\n",
            "           7     0.8308    0.7755    0.8022       842\n",
            "           8     0.9404    0.8095    0.8701       273\n",
            "           9     0.9148    0.9508    0.9324      1219\n",
            "          10     0.8953    0.9812    0.9363      1116\n",
            "\n",
            "    accuracy                         0.8665      6272\n",
            "   macro avg     0.7331    0.7261    0.7267      6272\n",
            "weighted avg     0.8666    0.8665    0.8654      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:49,  2.35it/s]\n",
            "196it [00:28,  6.96it/s]\n",
            "Epoch: [14/20], Intent Val Acc: 85.92 \t Slot F1 score: 87.12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8328    0.7697    0.8000       343\n",
            "           1     0.7517    0.7388    0.7452       291\n",
            "           2     0.8767    0.7252    0.7938       353\n",
            "           3     0.8503    0.8466    0.8485       906\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8278    0.8422    0.8349       925\n",
            "           6     0.0588    0.5000    0.1053         2\n",
            "           7     0.8074    0.7767    0.7918       842\n",
            "           8     0.9383    0.8291    0.8803       275\n",
            "           9     0.9200    0.9351    0.9275      1218\n",
            "          10     0.9020    0.9722    0.9358      1117\n",
            "\n",
            "    accuracy                         0.8592      6272\n",
            "   macro avg     0.7060    0.7214    0.6966      6272\n",
            "weighted avg     0.8635    0.8592    0.8604      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "373it [02:37,  2.36it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANenhdJcLQfW"
      },
      "source": [
        "# Hyperparameters Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQtK0JrxCZzJ"
      },
      "source": [
        "import random\n",
        "\n",
        "results = []\n",
        "for _ in range(10):\n",
        "    ne = 7\n",
        "    bs = random.choice([16])\n",
        "    wed = random.choice([100])\n",
        "    ehd = random.choice([192, 256])\n",
        "    lr = random.uniform(1e-4, 1e-2)\n",
        "\n",
        "    print(bs, wed, ehd)\n",
        "\n",
        "    !cd drive/MyDrive/Development/ID_in_CRS/Bi-Model-Intent-And-Slot && python train_args.py -te {ne} -bb {bs} -es {wed} -lhs {ehd}\n",
        "\n",
        "    print(\"#\" * 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9MobZuvFxVV"
      },
      "source": [
        "# Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uML1IhNbxDyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0001a6d-ad1a-4258-fd33-b04cbe9132db"
      },
      "source": [
        "!pip install fasttext > /dev/null"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 47.7 s (started: 2021-09-10 14:54:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHGuPIpyKqYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a37d3c-e301-4f51-d9c9-2f6998b18fe5"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import fasttext\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.88 ms (started: 2021-09-10 15:07:07 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPcyk4BYK5GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63061a0f-d755-4503-d556-ac2e0324991c"
      },
      "source": [
        "data_path = \"drive/MyDrive/Datasets/MultiWOZ_2.2_v2\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.22 ms (started: 2021-09-10 14:55:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Fpr3trKfNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f271917-845b-44d0-c9d7-da90752a8cac"
      },
      "source": [
        "with open(f\"{data_path}/train.json\", \"r\") as json_file:\n",
        "    train_data = json.load(json_file)\n",
        "with open(f\"{data_path}/validation.json\", \"r\") as json_file:\n",
        "    val_data = json.load(json_file)\n",
        "with open(f\"{data_path}/test.json\", \"r\") as json_file:\n",
        "    test_data = json.load(json_file)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.05 s (started: 2021-09-10 15:07:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A75TgIDFKixc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b443cde-0b20-42a3-ef3f-5ca071ae58b5"
      },
      "source": [
        "intent_label = \"intents\"\n",
        "\n",
        "def read_data(data):\n",
        "    X, y = [], []\n",
        "\n",
        "    for id, dlg in data.items():\n",
        "        for trn in dlg:\n",
        "            if trn[\"speaker\"] == 1:\n",
        "                continue\n",
        "\n",
        "            if len(trn[intent_label]) > 1:\n",
        "                continue\n",
        "\n",
        "            X.append(\" \".join(trn[\"words\"]))\n",
        "            if len(trn[intent_label]) == 1:\n",
        "                y.append(trn[intent_label][0])\n",
        "            else:\n",
        "                y.append(\"general\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = read_data(train_data)\n",
        "X_val, y_val = read_data(val_data)\n",
        "X_test, y_test = read_data(test_data)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 105 ms (started: 2021-09-10 15:08:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnGf4hilPbu9",
        "outputId": "e0974263-4c84-4429-d80d-e3b55f52b3d8"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_val = encoder.transform(y_val)\n",
        "y_test = encoder.transform(y_test)\n",
        "\n",
        "{class_name: idx for idx, class_name in enumerate(encoder.classes_)}"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'book_hotel': 0,\n",
              " 'book_restaurant': 1,\n",
              " 'book_train': 2,\n",
              " 'find_attraction': 3,\n",
              " 'find_hospital': 4,\n",
              " 'find_hotel': 5,\n",
              " 'find_police': 6,\n",
              " 'find_restaurant': 7,\n",
              " 'find_taxi': 8,\n",
              " 'find_train': 9,\n",
              " 'general': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 45.3 ms (started: 2021-09-10 15:08:34 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_bXupE0FvLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b87d8b5-3b0e-43c4-92ae-bb1a1f6af208"
      },
      "source": [
        "def prepare_fasttext_file(filename, X, Y):\n",
        "    with open(f\"{filename}.txt\", \"w\") as txt_file:\n",
        "        for x, y in zip(X, Y):\n",
        "            txt_file.write(f\"__label__{y} {x}\\n\")\n",
        "\n",
        "prepare_fasttext_file(\"train\", X_train, y_train)\n",
        "prepare_fasttext_file(\"val\", X_val, y_val)\n",
        "prepare_fasttext_file(\"test\", X_test, y_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 66.5 ms (started: 2021-09-10 15:08:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbcgjNLDtR94",
        "outputId": "110c19ae-fa4b-495a-e898-d183ff02f6fe"
      },
      "source": [
        "import gc\n",
        "\n",
        "del train_data, X_train, y_train\n",
        "del val_data, X_val, y_val\n",
        "del test_data\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 127 ms (started: 2021-09-10 14:57:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znDeWlnqKTN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be07e8ed-201c-4481-bb5f-948ad3e5b5cc"
      },
      "source": [
        "model = fasttext.train_supervised(\n",
        "    input=\"train.txt\",\n",
        "    autotuneValidationFile=\"val.txt\",\n",
        "    epoch=3\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5min 11s (started: 2021-09-10 15:10:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ZbdvXoLFVg",
        "outputId": "df17e0d2-85c6-4842-c12c-bc14815c2658"
      },
      "source": [
        "preds, _ = model.predict(X_test)\n",
        "preds = np.array([int(pred_label[0][-1]) for pred_label in preds])\n",
        "print(classification_report(y_test, preds, digits=4))\n",
        "print(confusion_matrix(y_test, preds))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.1776    0.7902    0.2901       348\n",
            "           1     0.8548    0.7235    0.7837       293\n",
            "           2     0.8204    0.7423    0.7794       357\n",
            "           3     0.8619    0.8468    0.8543       914\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8396    0.8512    0.8454       941\n",
            "           6     0.5000    0.5000    0.5000         2\n",
            "           7     0.8163    0.7981    0.8071       852\n",
            "           8     0.9512    0.8357    0.8897       280\n",
            "           9     0.9136    0.9455    0.9293      1230\n",
            "          10     0.0000    0.0000    0.0000      1121\n",
            "\n",
            "    accuracy                         0.6950      6338\n",
            "   macro avg     0.6123    0.6394    0.6072      6338\n",
            "weighted avg     0.6737    0.6950    0.6731      6338\n",
            "\n",
            "[[ 275    8   12    5    0   35    0    7    1    5    0]\n",
            " [  27  212   12    2    0    3    0   31    1    5    0]\n",
            " [  23    6  265    2    0    1    0    0    0   60    0]\n",
            " [  29    0    2  774    7   31    1   62    3    5    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  26    2    8   47    1  801    0   47    1    8    0]\n",
            " [   1    0    0    0    0    0    1    0    0    0    0]\n",
            " [  22   15    2   57    4   66    0  680    2    4    0]\n",
            " [  13    2    1    6    0    2    0    1  234   21    0]\n",
            " [  28    2   19    2    0   12    0    1    3 1163    0]\n",
            " [1104    1    2    3    1    3    0    4    1    2    0]]\n",
            "time: 472 ms (started: 2021-09-10 15:15:36 +00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Zz7jniPuv9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}