{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "J9Ff_-RRI1QU",
        "VP7uk63z7coq",
        "dOH3matWFggx",
        "o9MobZuvFxVV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiuV7fpUAR1v",
        "outputId": "bec1fd72-f8b7-463d-f7db-edca0f716294"
      },
      "source": [
        "!pip install ipython-autotime > /dev/null\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 224 µs (started: 2021-08-27 13:58:52 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Ff_-RRI1QU"
      },
      "source": [
        "# [A Stack-Propagation Framework with Token-Level Intent Detection for Spoken Language Understanding](https://github.com/LeePleased/StackPropagation-SLU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nz7WcVaIbgO"
      },
      "source": [
        "# !git clone https://github.com/amiralikaboli/StackPropagation-SLU.git drive/MyDrive/Dev/ID_in_CRS/StackPropagation-SLU > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE3kMTfQLjy8"
      },
      "source": [
        "!pip install ordered_set > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiJbGFlYMuyP"
      },
      "source": [
        "import random\n",
        "\n",
        "results = []\n",
        "for _ in range(10):\n",
        "    ne = 10\n",
        "    bs = random.choice([16, 32, 64])\n",
        "    wed = random.choice([30, 50, 100])\n",
        "    ehd = random.choice([64, 128, 256])\n",
        "\n",
        "    print(ne, bs, wed, ehd)\n",
        "\n",
        "    !cd drive/MyDrive/Dev/ID_in_CRS/StackPropagation-SLU && python train.py -dd ../../../Datasets/MultiWOZ_2.2 -ne {ne} -bs {bs} -wed {wed} -ehd {ehd}\n",
        "\n",
        "    print(\"#\" * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR6eQYCrJXIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dccb76d-bed3-449c-8a18-a7f13d820ea3"
      },
      "source": [
        "!pip install ordered_set > /dev/null\n",
        "!cd drive/MyDrive/Dev/ID_in_CRS/StackPropagation-SLU && python train.py -dd ../../../Datasets/MultiWOZ_2.2 -bs 64 -wed 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training parameters are listed as follows:\n",
            "\n",
            "\tnumber of train sample:                    38810;\n",
            "\tnumber of dev sample:                      5100;\n",
            "\tnumber of test sample:                     5117;\n",
            "\tnumber of epoch:\t\t\t\t\t\t    300;\n",
            "\tbatch size:\t\t\t\t\t\t\t    64;\n",
            "\tlearning rate:\t\t\t\t\t\t\t    0.001;\n",
            "\trandom seed:\t\t\t\t\t\t\t    0;\n",
            "\trate of l2 penalty:\t\t\t\t\t    1e-06;\n",
            "\trate of dropout in network:                0.4;\n",
            "\tteacher forcing rate(slot)\t\t    \t\t0.9;\n",
            "\tteacher forcing rate(intent):\t\t    \t0.9;\n",
            "\n",
            "End of parameters show. Save dir: save.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Model parameters are listed as follows:\n",
            "\n",
            "\tnumber of word:                            2315;\n",
            "\tnumber of slot:                            59;\n",
            "\tnumber of intent:\t\t\t\t\t\t    8;\n",
            "\tword embedding dimension:\t\t\t\t    100;\n",
            "\tencoder hidden dimension:\t\t\t\t    256;\n",
            "\tdimension of intent embedding:\t\t    \t8;\n",
            "\tdimension of slot embedding:\t\t\t    32;\n",
            "\tdimension of slot decoder hidden:  \t    64;\n",
            "\tdimension of intent decoder hidden:        64;\n",
            "\thidden dimension of self-attention:        1024;\n",
            "\toutput dimension of self-attention:        128;\n",
            "\n",
            "End of parameters show. Now training begins.\n",
            "\n",
            "\n",
            "The model has been loaded into GPU and cost 3.268241 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [03:08<00:00,  3.23it/s]\n",
            "[Epoch  0]: The total slot loss on train data is 305.160902, intent data is 301.419485, cost about 188.162 seconds.\n",
            "100%|█████████████| 80/80 [00:49<00:00,  1.60it/s]\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.58it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8147    0.6914    0.7480       337\n",
            "book_restaurant     0.9112    0.7040    0.7943       277\n",
            "     book_train     0.7684    0.6348    0.6952       345\n",
            "find_attraction     0.7079    0.9419    0.8083       929\n",
            "     find_hotel     0.8305    0.8068    0.8185       911\n",
            "find_restaurant     0.8507    0.7251    0.7829       833\n",
            "      find_taxi     0.9814    0.5788    0.7281       273\n",
            "     find_train     0.8634    0.9546    0.9067      1212\n",
            "\n",
            "       accuracy                         0.8161      5117\n",
            "      macro avg     0.8410    0.7547    0.7853      5117\n",
            "   weighted avg     0.8265    0.8161    0.8127      5117\n",
            "\n",
            "Test result: slot f1 score: 0.639852, intent acc score: 0.816103, semantic accuracy score: 0.476451.\n",
            "[Epoch  0]: In validation process, the slot f1 score is 0.633977, the intent acc is 0.813725, the semantic acc is 0.47, cost about 103.411766 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [03:08<00:00,  3.22it/s]\n",
            "[Epoch  1]: The total slot loss on train data is 98.715092, intent data is 117.879722, cost about 188.617 seconds.\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.57it/s]\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.55it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8567    0.7448    0.7968       337\n",
            "book_restaurant     0.7993    0.7762    0.7875       277\n",
            "     book_train     0.7265    0.7623    0.7440       345\n",
            "find_attraction     0.7719    0.9397    0.8476       929\n",
            "     find_hotel     0.9178    0.7717    0.8384       911\n",
            "find_restaurant     0.8166    0.7911    0.8037       833\n",
            "      find_taxi     0.9855    0.7473    0.8500       273\n",
            "     find_train     0.9048    0.9571    0.9302      1212\n",
            "\n",
            "       accuracy                         0.8458      5117\n",
            "      macro avg     0.8474    0.8113    0.8248      5117\n",
            "   weighted avg     0.8520    0.8458    0.8449      5117\n",
            "\n",
            "Test result: slot f1 score: 0.836071, intent acc score: 0.845808, semantic accuracy score: 0.678132.\n",
            "[Epoch  1]: In validation process, the slot f1 score is 0.841692, the intent acc is 0.847451, the semantic acc is 0.68, cost about 104.298350 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [03:06<00:00,  3.26it/s]\n",
            "[Epoch  2]: The total slot loss on train data is 62.683630, intent data is 90.485995, cost about 186.465 seconds.\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.56it/s]\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.57it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8155    0.7478    0.7802       337\n",
            "book_restaurant     0.8686    0.7401    0.7992       277\n",
            "     book_train     0.7342    0.7768    0.7549       345\n",
            "find_attraction     0.8565    0.8482    0.8524       929\n",
            "     find_hotel     0.9235    0.7816    0.8466       911\n",
            "find_restaurant     0.7256    0.8571    0.7859       833\n",
            "      find_taxi     0.8915    0.8425    0.8663       273\n",
            "     find_train     0.9105    0.9571    0.9332      1212\n",
            "\n",
            "       accuracy                         0.8460      5117\n",
            "      macro avg     0.8408    0.8189    0.8273      5117\n",
            "   weighted avg     0.8515    0.8460    0.8462      5117\n",
            "\n",
            "Test result: slot f1 score: 0.856796, intent acc score: 0.846004, semantic accuracy score: 0.702169.\n",
            "[Epoch  2]: In validation process, the slot f1 score is 0.864619, the intent acc is 0.859412, the semantic acc is 0.72, cost about 103.819824 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [02:59<00:00,  3.38it/s]\n",
            "[Epoch  3]: The total slot loss on train data is 50.084385, intent data is 85.492482, cost about 179.582 seconds.\n",
            "100%|█████████████| 80/80 [00:49<00:00,  1.62it/s]\n",
            "100%|█████████████| 80/80 [00:51<00:00,  1.54it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8019    0.7448    0.7723       337\n",
            "book_restaurant     0.8397    0.7942    0.8163       277\n",
            "     book_train     0.8084    0.7826    0.7953       345\n",
            "find_attraction     0.8473    0.8482    0.8478       929\n",
            "     find_hotel     0.8603    0.8178    0.8385       911\n",
            "find_restaurant     0.7552    0.8331    0.7922       833\n",
            "      find_taxi     0.9783    0.8242    0.8946       273\n",
            "     find_train     0.9121    0.9505    0.9309      1212\n",
            "\n",
            "       accuracy                         0.8491      5117\n",
            "      macro avg     0.8504    0.8244    0.8360      5117\n",
            "   weighted avg     0.8509    0.8491    0.8491      5117\n",
            "\n",
            "Test result: slot f1 score: 0.876383, intent acc score: 0.849130, semantic accuracy score: 0.720344.\n",
            "[Epoch  3]: In validation process, the slot f1 score is 0.883424, the intent acc is 0.863137, the semantic acc is 0.74, cost about 103.004993 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [03:08<00:00,  3.21it/s]\n",
            "[Epoch  4]: The total slot loss on train data is 43.634813, intent data is 75.288504, cost about 188.852 seconds.\n",
            "100%|█████████████| 80/80 [00:49<00:00,  1.61it/s]\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.57it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.7795    0.7656    0.7725       337\n",
            "book_restaurant     0.8571    0.7581    0.8046       277\n",
            "     book_train     0.8237    0.7855    0.8042       345\n",
            "find_attraction     0.8335    0.8891    0.8604       929\n",
            "     find_hotel     0.8888    0.8068    0.8458       911\n",
            "find_restaurant     0.7677    0.8211    0.7935       833\n",
            "      find_taxi     0.9741    0.8278    0.8950       273\n",
            "     find_train     0.9142    0.9587    0.9360      1212\n",
            "\n",
            "       accuracy                         0.8544      5117\n",
            "      macro avg     0.8548    0.8266    0.8390      5117\n",
            "   weighted avg     0.8563    0.8544    0.8541      5117\n",
            "\n",
            "Test result: slot f1 score: 0.880458, intent acc score: 0.854407, semantic accuracy score: 0.726793.\n",
            "[Epoch  4]: In validation process, the slot f1 score is 0.885263, the intent acc is 0.865098, the semantic acc is 0.75, cost about 102.340974 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [02:54<00:00,  3.47it/s]\n",
            "[Epoch  5]: The total slot loss on train data is 38.973229, intent data is 68.637916, cost about 174.696 seconds.\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.58it/s]\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.59it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8777    0.7240    0.7935       337\n",
            "book_restaurant     0.7401    0.8123    0.7745       277\n",
            "     book_train     0.8302    0.7797    0.8042       345\n",
            "find_attraction     0.7961    0.9290    0.8574       929\n",
            "     find_hotel     0.9338    0.7892    0.8554       911\n",
            "find_restaurant     0.8075    0.8007    0.8041       833\n",
            "      find_taxi     0.9431    0.8498    0.8940       273\n",
            "     find_train     0.9113    0.9662    0.9379      1212\n",
            "\n",
            "       accuracy                         0.8579      5117\n",
            "      macro avg     0.8550    0.8314    0.8401      5117\n",
            "   weighted avg     0.8622    0.8579    0.8571      5117\n",
            "\n",
            "Test result: slot f1 score: 0.884145, intent acc score: 0.857925, semantic accuracy score: 0.735196.\n",
            "[Epoch  5]: In validation process, the slot f1 score is 0.888263, the intent acc is 0.867843, the semantic acc is 0.75, cost about 102.382816 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [02:59<00:00,  3.39it/s]\n",
            "[Epoch  6]: The total slot loss on train data is 36.227159, intent data is 69.026109, cost about 179.102 seconds.\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.59it/s]\n",
            "100%|█████████████| 80/80 [00:49<00:00,  1.61it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8548    0.7685    0.8094       337\n",
            "book_restaurant     0.8486    0.7690    0.8068       277\n",
            "     book_train     0.8201    0.7797    0.7994       345\n",
            "find_attraction     0.8216    0.9322    0.8734       929\n",
            "     find_hotel     0.9070    0.8134    0.8576       911\n",
            "find_restaurant     0.8136    0.8067    0.8101       833\n",
            "      find_taxi     0.9617    0.8278    0.8898       273\n",
            "     find_train     0.9025    0.9703    0.9352      1212\n",
            "\n",
            "       accuracy                         0.8642      5117\n",
            "      macro avg     0.8662    0.8335    0.8477      5117\n",
            "   weighted avg     0.8657    0.8642    0.8630      5117\n",
            "\n",
            "Test result: slot f1 score: 0.888640, intent acc score: 0.864178, semantic accuracy score: 0.744577.\n",
            "[Epoch  6]: In validation process, the slot f1 score is 0.892499, the intent acc is 0.873725, the semantic acc is 0.76, cost about 101.476079 seconds.\n",
            "\n",
            "100%|███████████| 607/607 [02:45<00:00,  3.67it/s]\n",
            "[Epoch  7]: The total slot loss on train data is 33.642192, intent data is 60.761556, cost about 165.304 seconds.\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.59it/s]\n",
            "100%|█████████████| 80/80 [00:50<00:00,  1.58it/s]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     book_hotel     0.8302    0.7834    0.8061       337\n",
            "book_restaurant     0.8945    0.7653    0.8249       277\n",
            "     book_train     0.8462    0.7652    0.8037       345\n",
            "find_attraction     0.8199    0.9214    0.8677       929\n",
            "     find_hotel     0.9245    0.7925    0.8534       911\n",
            "find_restaurant     0.8035    0.8199    0.8116       833\n",
            "      find_taxi     0.9826    0.8278    0.8986       273\n",
            "     find_train     0.8818    0.9785    0.9276      1212\n",
            "\n",
            "       accuracy                         0.8624      5117\n",
            "      macro avg     0.8729    0.8318    0.8492      5117\n",
            "   weighted avg     0.8657    0.8624    0.8612      5117\n",
            "\n",
            "Test result: slot f1 score: 0.889618, intent acc score: 0.862419, semantic accuracy score: 0.744772.\n",
            "[Epoch  7]: In validation process, the slot f1 score is 0.891392, the intent acc is 0.875294, the semantic acc is 0.76, cost about 102.321093 seconds.\n",
            "\n",
            " 98%|██████████▊| 594/607 [02:44<00:05,  2.41it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP7uk63z7coq"
      },
      "source": [
        "# [A Co-Interactive Transformer for Joint Slot Filling and Intent Detection](https://github.com/kangbrilliant/DCA-Net)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ123bAzJjBH"
      },
      "source": [
        "# !git clone https://github.com/amiralikaboli/DCA-Net.git drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADeMCfaZJvKF"
      },
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !cp drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets download thanakomsn/glove6b300dtxt > /dev/null\n",
        "# !unzip glove6b300dtxt.zip -d drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer/data > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJgzY0GQ6WFO"
      },
      "source": [
        "# import json\n",
        "\n",
        "# src_path = \"drive/MyDrive/Datasets/MultiWOZ_2.2\"\n",
        "# dst_path = \"drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer/data\"\n",
        "\n",
        "# intent_label = \"intents\"\n",
        "# slot_label = \"slots1\"\n",
        "\n",
        "\n",
        "# vocab = [\"<pad>\", \"<unk>\", \"</s>\", \"</e>\"]\n",
        "# with open(f\"{src_path}/words.json\", \"r\") as json_file:\n",
        "#     vocab.extend(json.load(json_file))\n",
        "# with open(f\"{dst_path}/vocab.txt\", \"w\") as txt_file:\n",
        "#     txt_file.writelines([f\"{word}\\n\" for word in vocab])\n",
        "\n",
        "# intents = [\"general\"]\n",
        "# with open(f\"{src_path}/{intent_label}.json\", \"r\") as json_file:\n",
        "#     intents.extend(json.load(json_file))\n",
        "# with open(f\"{dst_path}/intent_label.txt\", \"w\") as txt_file:\n",
        "#     txt_file.writelines([f\"{idx}\\t{intent}\\n\" for idx, intent in enumerate(intents)])\n",
        "\n",
        "# slots = [\"<PAD>\", \"<start>\", \"<end>\"]\n",
        "# with open(f\"{src_path}/{slot_label}.json\", \"r\") as json_file:\n",
        "#     slots.extend(json.load(json_file))\n",
        "# with open(f\"{dst_path}/slot_label.txt\", \"w\") as txt_file:\n",
        "#     txt_file.writelines([f\"{idx}\\t{slot}\\n\" for idx, slot in enumerate(slots)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr7PB6TwJ0UG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422e062d-2b9f-41d5-a73d-403a68b4b26c"
      },
      "source": [
        "!cd drive/MyDrive/Dev/ID_in_CRS/CoInteractive-Transformer && python main_joint.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0% 0/20 [00:00<?, ?it/s][0.001]\n",
            "100% 1213/1213 [01:02<00:00, 19.36it/s]\n",
            "100% 160/160 [00:08<00:00, 19.97it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8416    0.6115    0.7083       278\n",
            "           2     0.6272    0.9203    0.7460       903\n",
            "           3     0.8006    0.6327    0.7068       863\n",
            "           4     0.9010    0.7182    0.7993       912\n",
            "           5     0.8691    0.8951    0.8819      1172\n",
            "           6     0.6675    0.8275    0.7389       342\n",
            "           7     0.8391    0.7065    0.7671       310\n",
            "           8     0.8787    0.7469    0.8074       320\n",
            "\n",
            "    accuracy                         0.7827      5100\n",
            "   macro avg     0.8031    0.7573    0.7695      5100\n",
            "weighted avg     0.8041    0.7827    0.7827      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.610308 slot_loss: 1.634842 acc: 0.7827% slot f1: 0.7749 sent acc: 0.5806 \n",
            "\n",
            "Epoch:   5% 1/20 [01:12<22:49, 72.06s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.82it/s]\n",
            "100% 160/160 [00:07<00:00, 20.21it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7711    0.6906    0.7287       278\n",
            "           2     0.8063    0.7099    0.7550       903\n",
            "           3     0.6285    0.8273    0.7144       863\n",
            "           4     0.8201    0.7500    0.7835       912\n",
            "           5     0.9007    0.8899    0.8953      1172\n",
            "           6     0.7358    0.8304    0.7802       342\n",
            "           7     0.8068    0.7677    0.7868       310\n",
            "           8     0.9312    0.7188    0.8113       320\n",
            "\n",
            "    accuracy                         0.7894      5100\n",
            "   macro avg     0.8001    0.7731    0.7819      5100\n",
            "weighted avg     0.8016    0.7894    0.7912      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.539832 slot_loss: 1.258028 acc: 0.7894% slot f1: 0.8108 sent acc: 0.6141 \n",
            "\n",
            "Epoch:  10% 2/20 [02:21<21:25, 71.42s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.78it/s]\n",
            "100% 160/160 [00:07<00:00, 20.47it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.6337    0.7842    0.7010       278\n",
            "           2     0.8914    0.6633    0.7606       903\n",
            "           3     0.6400    0.8239    0.7204       863\n",
            "           4     0.8200    0.7643    0.7911       912\n",
            "           5     0.8907    0.9249    0.9075      1172\n",
            "           6     0.7631    0.8099    0.7858       342\n",
            "           7     0.9153    0.7323    0.8136       310\n",
            "           8     0.8542    0.7875    0.8195       320\n",
            "\n",
            "    accuracy                         0.7971      5100\n",
            "   macro avg     0.8011    0.7863    0.7874      5100\n",
            "weighted avg     0.8124    0.7971    0.7984      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.525633 slot_loss: 1.152172 acc: 0.7971% slot f1: 0.8195 sent acc: 0.6271 \n",
            "\n",
            "Epoch:  15% 3/20 [03:31<20:06, 70.98s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.83it/s]\n",
            "100% 160/160 [00:07<00:00, 20.44it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7407    0.7914    0.7652       278\n",
            "           2     0.8638    0.6955    0.7706       903\n",
            "           3     0.6774    0.8053    0.7358       863\n",
            "           4     0.8364    0.7961    0.8157       912\n",
            "           5     0.8605    0.9420    0.8994      1172\n",
            "           6     0.7115    0.8509    0.7750       342\n",
            "           7     0.9270    0.6968    0.7956       310\n",
            "           8     0.9416    0.7562    0.8388       320\n",
            "\n",
            "    accuracy                         0.8082      5100\n",
            "   macro avg     0.8199    0.7918    0.7995      5100\n",
            "weighted avg     0.8184    0.8082    0.8082      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.507012 slot_loss: 1.063450 acc: 0.8082% slot f1: 0.8260 sent acc: 0.6410 \n",
            "\n",
            "Epoch:  20% 4/20 [04:41<18:49, 70.62s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.76it/s]\n",
            "100% 160/160 [00:08<00:00, 19.25it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8559    0.7050    0.7732       278\n",
            "           2     0.6846    0.9280    0.7880       903\n",
            "           3     0.8336    0.6674    0.7413       863\n",
            "           4     0.8937    0.7467    0.8136       912\n",
            "           5     0.8703    0.9386    0.9031      1172\n",
            "           6     0.7019    0.8538    0.7704       342\n",
            "           7     0.9351    0.6968    0.7985       310\n",
            "           8     0.8799    0.7781    0.8259       320\n",
            "\n",
            "    accuracy                         0.8133      5100\n",
            "   macro avg     0.8319    0.7893    0.8018      5100\n",
            "weighted avg     0.8278    0.8133    0.8122      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.490853 slot_loss: 1.047546 acc: 0.8133% slot f1: 0.8210 sent acc: 0.6380 \n",
            "\n",
            "Epoch:  25% 5/20 [05:51<17:36, 70.42s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 20.00it/s]\n",
            "100% 160/160 [00:08<00:00, 19.24it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8714    0.7554    0.8092       278\n",
            "           2     0.7342    0.8904    0.8048       903\n",
            "           3     0.8183    0.7045    0.7572       863\n",
            "           4     0.8248    0.7950    0.8096       912\n",
            "           5     0.8859    0.9275    0.9062      1172\n",
            "           6     0.8235    0.8187    0.8211       342\n",
            "           7     0.8964    0.7258    0.8021       310\n",
            "           8     0.8056    0.8156    0.8106       320\n",
            "\n",
            "    accuracy                         0.8235      5100\n",
            "   macro avg     0.8325    0.8041    0.8151      5100\n",
            "weighted avg     0.8273    0.8235    0.8224      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.478960 slot_loss: 1.007242 acc: 0.8235% slot f1: 0.8329 sent acc: 0.6590 \n",
            "\n",
            "Epoch:  30% 6/20 [07:01<16:23, 70.24s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.93it/s]\n",
            "100% 160/160 [00:08<00:00, 19.21it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8226    0.7842    0.8029       278\n",
            "           2     0.7057    0.8948    0.7891       903\n",
            "           3     0.7881    0.7242    0.7548       863\n",
            "           4     0.9329    0.7160    0.8102       912\n",
            "           5     0.8850    0.9258    0.9049      1172\n",
            "           6     0.8919    0.7719    0.8276       342\n",
            "           7     0.8980    0.7097    0.7928       310\n",
            "           8     0.6326    0.8500    0.7253       320\n",
            "\n",
            "    accuracy                         0.8127      5100\n",
            "   macro avg     0.8196    0.7971    0.8010      5100\n",
            "weighted avg     0.8274    0.8127    0.8132      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.499732 slot_loss: 0.994970 acc: 0.8127% slot f1: 0.8286 sent acc: 0.6543 \n",
            "\n",
            "Epoch:  35% 7/20 [08:10<15:09, 69.98s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.91it/s]\n",
            "100% 160/160 [00:08<00:00, 19.17it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8486    0.7662    0.8053       278\n",
            "           2     0.7390    0.8904    0.8076       903\n",
            "           3     0.7903    0.7161    0.7514       863\n",
            "           4     0.8552    0.7708    0.8108       912\n",
            "           5     0.8567    0.9488    0.9004      1172\n",
            "           6     0.8069    0.8187    0.8128       342\n",
            "           7     0.9636    0.6839    0.8000       310\n",
            "           8     0.8562    0.7812    0.8170       320\n",
            "\n",
            "    accuracy                         0.8220      5100\n",
            "   macro avg     0.8396    0.7970    0.8132      5100\n",
            "weighted avg     0.8270    0.8220    0.8203      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.474137 slot_loss: 0.968669 acc: 0.8220% slot f1: 0.8291 sent acc: 0.6594 \n",
            "\n",
            "Epoch:  40% 8/20 [09:20<13:58, 69.84s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.90it/s]\n",
            "100% 160/160 [00:08<00:00, 19.56it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7329    0.8489    0.7867       278\n",
            "           2     0.8418    0.7364    0.7856       903\n",
            "           3     0.6423    0.8552    0.7336       863\n",
            "           4     0.9377    0.7259    0.8183       912\n",
            "           5     0.8760    0.9403    0.9070      1172\n",
            "           6     0.8394    0.8099    0.8244       342\n",
            "           7     0.8571    0.6968    0.7687       310\n",
            "           8     0.8737    0.8000    0.8352       320\n",
            "\n",
            "    accuracy                         0.8141      5100\n",
            "   macro avg     0.8251    0.8017    0.8074      5100\n",
            "weighted avg     0.8299    0.8141    0.8153      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.486247 slot_loss: 0.941523 acc: 0.8141% slot f1: 0.8344 sent acc: 0.6673 \n",
            "\n",
            "Epoch:  45% 9/20 [10:30<12:47, 69.78s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.94it/s]\n",
            "100% 160/160 [00:08<00:00, 19.98it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7240    0.8022    0.7611       278\n",
            "           2     0.8792    0.7331    0.7995       903\n",
            "           3     0.7052    0.7926    0.7463       863\n",
            "           4     0.8086    0.8202    0.8144       912\n",
            "           5     0.8667    0.9488    0.9059      1172\n",
            "           6     0.8323    0.8129    0.8225       342\n",
            "           7     0.8935    0.7581    0.8202       310\n",
            "           8     0.9242    0.7625    0.8356       320\n",
            "\n",
            "    accuracy                         0.8208      5100\n",
            "   macro avg     0.8292    0.8038    0.8132      5100\n",
            "weighted avg     0.8264    0.8208    0.8206      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.479173 slot_loss: 0.932941 acc: 0.8208% slot f1: 0.8363 sent acc: 0.6649 \n",
            "\n",
            "Epoch:  50% 10/20 [11:39<11:35, 69.57s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.85it/s]\n",
            "100% 160/160 [00:07<00:00, 20.21it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8228    0.7518    0.7857       278\n",
            "           2     0.8359    0.7674    0.8002       903\n",
            "           3     0.6748    0.8366    0.7470       863\n",
            "           4     0.9183    0.7522    0.8270       912\n",
            "           5     0.8544    0.9565    0.9026      1172\n",
            "           6     0.9266    0.7749    0.8439       342\n",
            "           7     0.9208    0.7129    0.8036       310\n",
            "           8     0.7541    0.8531    0.8006       320\n",
            "\n",
            "    accuracy                         0.8216      5100\n",
            "   macro avg     0.8385    0.8007    0.8138      5100\n",
            "weighted avg     0.8330    0.8216    0.8219      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.469864 slot_loss: 0.915240 acc: 0.8216% slot f1: 0.8417 sent acc: 0.6708 \n",
            "\n",
            "Epoch:  55% 11/20 [12:48<10:26, 69.57s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.84it/s]\n",
            "100% 160/160 [00:08<00:00, 19.61it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8583    0.7626    0.8076       278\n",
            "           2     0.7924    0.8117    0.8020       903\n",
            "           3     0.7620    0.7346    0.7481       863\n",
            "           4     0.7719    0.8388    0.8040       912\n",
            "           5     0.8850    0.9386    0.9110      1172\n",
            "           6     0.9003    0.7924    0.8429       342\n",
            "           7     0.9325    0.7129    0.8080       310\n",
            "           8     0.8117    0.8219    0.8168       320\n",
            "\n",
            "    accuracy                         0.8233      5100\n",
            "   macro avg     0.8393    0.8017    0.8175      5100\n",
            "weighted avg     0.8254    0.8233    0.8226      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.463904 slot_loss: 0.917905 acc: 0.8233% slot f1: 0.8384 sent acc: 0.6682 \n",
            "\n",
            "Epoch:  60% 12/20 [13:58<09:16, 69.55s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.91it/s]\n",
            "100% 160/160 [00:08<00:00, 19.27it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7404    0.8309    0.7831       278\n",
            "           2     0.8333    0.8140    0.8235       903\n",
            "           3     0.7692    0.7764    0.7728       863\n",
            "           4     0.8239    0.8257    0.8248       912\n",
            "           5     0.8631    0.9471    0.9032      1172\n",
            "           6     0.8344    0.7953    0.8144       342\n",
            "           7     0.9646    0.7032    0.8134       310\n",
            "           8     0.8763    0.7750    0.8226       320\n",
            "\n",
            "    accuracy                         0.8308      5100\n",
            "   macro avg     0.8382    0.8084    0.8197      5100\n",
            "weighted avg     0.8333    0.8308    0.8300      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.471990 slot_loss: 0.921869 acc: 0.8308% slot f1: 0.8370 sent acc: 0.6816 \n",
            "\n",
            "Epoch:  65% 13/20 [15:07<08:07, 69.61s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.97it/s]\n",
            "100% 160/160 [00:08<00:00, 19.20it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7585    0.8022    0.7797       278\n",
            "           2     0.8152    0.8062    0.8107       903\n",
            "           3     0.7131    0.8297    0.7670       863\n",
            "           4     0.9081    0.7588    0.8268       912\n",
            "           5     0.8719    0.9411    0.9052      1172\n",
            "           6     0.8299    0.8275    0.8287       342\n",
            "           7     0.9163    0.7065    0.7978       310\n",
            "           8     0.8510    0.8031    0.8264       320\n",
            "\n",
            "    accuracy                         0.8276      5100\n",
            "   macro avg     0.8330    0.8094    0.8178      5100\n",
            "weighted avg     0.8339    0.8276    0.8276      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.464215 slot_loss: 0.908996 acc: 0.8276% slot f1: 0.8379 sent acc: 0.6753 \n",
            "\n",
            "Epoch:  70% 14/20 [16:17<06:57, 69.51s/it][0.001]\n",
            "100% 1213/1213 [01:02<00:00, 19.54it/s]\n",
            "100% 160/160 [00:07<00:00, 20.56it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7451    0.8201    0.7808       278\n",
            "           2     0.7924    0.8583    0.8240       903\n",
            "           3     0.7799    0.7555    0.7675       863\n",
            "           4     0.8844    0.7719    0.8244       912\n",
            "           5     0.8849    0.9317    0.9077      1172\n",
            "           6     0.8778    0.7982    0.8361       342\n",
            "           7     0.7440    0.8065    0.7740       310\n",
            "           8     0.8383    0.7937    0.8154       320\n",
            "\n",
            "    accuracy                         0.8290      5100\n",
            "   macro avg     0.8184    0.8170    0.8162      5100\n",
            "weighted avg     0.8311    0.8290    0.8286      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.472922 slot_loss: 0.874233 acc: 0.8290% slot f1: 0.8454 sent acc: 0.6859 \n",
            "\n",
            "Epoch:  75% 15/20 [17:27<05:48, 69.77s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.75it/s]\n",
            "100% 160/160 [00:07<00:00, 20.23it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7569    0.7842    0.7703       278\n",
            "           2     0.8171    0.8261    0.8216       903\n",
            "           3     0.7440    0.7949    0.7686       863\n",
            "           4     0.8846    0.7730    0.8250       912\n",
            "           5     0.8502    0.9633    0.9032      1172\n",
            "           6     0.8240    0.8216    0.8228       342\n",
            "           7     0.9683    0.6903    0.8060       310\n",
            "           8     0.8759    0.7937    0.8328       320\n",
            "\n",
            "    accuracy                         0.8300      5100\n",
            "   macro avg     0.8401    0.8059    0.8188      5100\n",
            "weighted avg     0.8345    0.8300    0.8290      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.460229 slot_loss: 0.864823 acc: 0.8300% slot f1: 0.8400 sent acc: 0.6829 \n",
            "\n",
            "Epoch:  80% 16/20 [18:37<04:38, 69.69s/it][0.001]\n",
            "100% 1213/1213 [01:01<00:00, 19.86it/s]\n",
            "100% 160/160 [00:07<00:00, 20.60it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7321    0.8453    0.7846       278\n",
            "           2     0.7361    0.9269    0.8206       903\n",
            "           3     0.8426    0.7010    0.7653       863\n",
            "           4     0.8433    0.7851    0.8132       912\n",
            "           5     0.8862    0.9300    0.9076      1172\n",
            "           6     0.8669    0.8187    0.8421       342\n",
            "           7     0.8864    0.7548    0.8153       310\n",
            "           8     0.9341    0.7531    0.8339       320\n",
            "\n",
            "    accuracy                         0.8310      5100\n",
            "   macro avg     0.8410    0.8144    0.8228      5100\n",
            "weighted avg     0.8379    0.8310    0.8299      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.452673 slot_loss: 0.883552 acc: 0.8310% slot f1: 0.8390 sent acc: 0.6827 \n",
            "\n",
            "Epoch:  85% 17/20 [19:46<03:28, 69.51s/it][0.001]\n",
            "100% 1213/1213 [01:00<00:00, 19.91it/s]\n",
            "100% 160/160 [00:07<00:00, 20.58it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8116    0.8058    0.8087       278\n",
            "           2     0.7810    0.8571    0.8173       903\n",
            "           3     0.7636    0.7787    0.7711       863\n",
            "           4     0.8799    0.7632    0.8174       912\n",
            "           5     0.8609    0.9505    0.9035      1172\n",
            "           6     0.8671    0.8012    0.8328       342\n",
            "           7     0.8654    0.7258    0.7895       310\n",
            "           8     0.8596    0.7844    0.8203       320\n",
            "\n",
            "    accuracy                         0.8294      5100\n",
            "   macro avg     0.8361    0.8083    0.8201      5100\n",
            "weighted avg     0.8316    0.8294    0.8284      5100\n",
            "\n",
            "\n",
            "Evaluation - intent_loss: 0.460484 slot_loss: 0.886939 acc: 0.8294% slot f1: 0.8392 sent acc: 0.6827 \n",
            "\n",
            "Epoch:  90% 18/20 [20:55<02:18, 69.32s/it][0.001]\n",
            " 63% 765/1213 [00:38<00:21, 20.68it/s]Traceback (most recent call last):\n",
            "  File \"main_joint.py\", line 216, in <module>\n",
            "  File \"main_joint.py\", line 131, in run_train\n",
            "    loss_intent, loss_slot, = model.loss1(logits_intent, logits_slot, intent_labels, slot_labels, masks)\n",
            "  File \"/content/drive/My Drive/Development/ID_in_CRS/CoInteractive-Transformer/model/joint_model_trans.py\", line 59, in loss1\n",
            "    loss_slot = -self.crflayer(logits_slot, slot_label, mask) / logits_intent.size()[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/Development/ID_in_CRS/CoInteractive-Transformer/model/torch_crf.py\", line 117, in forward\n",
            "    denominator = self._compute_log_partition_function(emissions, mask)\n",
            "  File \"/content/drive/My Drive/Development/ID_in_CRS/CoInteractive-Transformer/model/torch_crf.py\", line 229, in _compute_log_partition_function\n",
            "    broadcast_transitions = self.transitions.unsqueeze(0)  # (1, num_tags, num_tags)\n",
            "KeyboardInterrupt\n",
            "Epoch:  90% 18/20 [21:34<02:23, 71.92s/it]\n",
            " 63% 765/1213 [00:39<00:23, 19.35it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOH3matWFggx"
      },
      "source": [
        "# [A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling](https://github.com/ray075hl/Bi-Model-Intent-And-Slot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d1fdudSKN4h"
      },
      "source": [
        "# !git clone https://github.com/amiralikaboli/Bi-Model-Intent-And-Slot.git drive/MyDrive/Dev/ID_in_CRS/Bi-Model-Intent-And-Slot  > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgKSPtKeKX9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe4d56d-3f0d-4717-ee75-c189dfb1e2f6"
      },
      "source": [
        "!cd drive/MyDrive/Dev/ID_in_CRS/Bi-Model-Intent-And-Slot && python train_args.py -te 20 -bb 32 -es 50 -lhs 192"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  48779\n",
            "Number of test samples:  6298\n",
            "Number of words:  1959\n",
            "Number of intent labels:  11\n",
            "Number of slot labels 60\n",
            "##################################################\n",
            "{'book_hotel': 0, 'book_restaurant': 1, 'book_train': 2, 'find_attraction': 3, 'find_hospital': 4, 'find_hotel': 5, 'find_police': 6, 'find_restaurant': 7, 'find_taxi': 8, 'find_train': 9, 'general': 10}\n",
            "1524it [10:48,  2.35it/s]\n",
            "196it [00:28,  6.93it/s]\n",
            "Epoch: [1/20], Intent Val Acc: 84.71 \t Slot F1 score: 83.81\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8274    0.7405    0.7815       343\n",
            "           1     0.8621    0.6873    0.7648       291\n",
            "           2     0.7805    0.7211    0.7496       355\n",
            "           3     0.8369    0.8248    0.8308       902\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.7904    0.8491    0.8187       928\n",
            "           6     0.0000    0.0000    0.0000         2\n",
            "           7     0.8078    0.7628    0.7846       843\n",
            "           8     1.0000    0.6606    0.7957       277\n",
            "           9     0.8791    0.9522    0.9142      1214\n",
            "          10     0.8919    0.9749    0.9316      1117\n",
            "\n",
            "    accuracy                         0.8471      6272\n",
            "   macro avg     0.6978    0.6521    0.6701      6272\n",
            "weighted avg     0.8485    0.8471    0.8447      6272\n",
            "\n",
            "Best Intent Acc: 84.71 at Epoch: [1]\n",
            "Best F1 score: 83.81 at Epoch: [1]\n",
            "**************************************************\n",
            "1524it [10:48,  2.35it/s]\n",
            "196it [00:28,  6.94it/s]\n",
            "Epoch: [2/20], Intent Val Acc: 85.59 \t Slot F1 score: 85.87\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8489    0.7719    0.8086       342\n",
            "           1     0.8477    0.7055    0.7701       292\n",
            "           2     0.8043    0.7358    0.7685       352\n",
            "           3     0.8468    0.8374    0.8420       904\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8178    0.8434    0.8304       926\n",
            "           6     0.2500    0.5000    0.3333         2\n",
            "           7     0.7854    0.7509    0.7677       843\n",
            "           8     0.9256    0.8087    0.8632       277\n",
            "           9     0.9005    0.9426    0.9210      1219\n",
            "          10     0.8989    0.9812    0.9383      1115\n",
            "\n",
            "    accuracy                         0.8559      6272\n",
            "   macro avg     0.7205    0.7161    0.7130      6272\n",
            "weighted avg     0.8550    0.8559    0.8543      6272\n",
            "\n",
            "Best Intent Acc: 85.59 at Epoch: [2]\n",
            "Best F1 score: 85.87 at Epoch: [2]\n",
            "**************************************************\n",
            "1524it [10:49,  2.35it/s]\n",
            "196it [00:28,  6.91it/s]\n",
            "Epoch: [3/20], Intent Val Acc: 85.83 \t Slot F1 score: 86.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8901    0.7168    0.7941       339\n",
            "           1     0.8061    0.7260    0.7640       292\n",
            "           2     0.8323    0.7429    0.7851       354\n",
            "           3     0.8331    0.8211    0.8271       900\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.9243    0.7750    0.8431       929\n",
            "           6     0.3333    0.5000    0.4000         2\n",
            "           7     0.7143    0.8600    0.7804       843\n",
            "           8     0.9426    0.8303    0.8829       277\n",
            "           9     0.9188    0.9475    0.9329      1218\n",
            "          10     0.8882    0.9803    0.9320      1118\n",
            "\n",
            "    accuracy                         0.8583      6272\n",
            "   macro avg     0.7348    0.7182    0.7220      6272\n",
            "weighted avg     0.8636    0.8583    0.8577      6272\n",
            "\n",
            "Best Intent Acc: 85.83 at Epoch: [3]\n",
            "Best F1 score: 86.95 at Epoch: [3]\n",
            "**************************************************\n",
            "1524it [10:49,  2.35it/s]\n",
            "196it [00:28,  6.94it/s]\n",
            "Epoch: [4/20], Intent Val Acc: 86.22 \t Slot F1 score: 86.73\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8168    0.7977    0.8071       341\n",
            "           1     0.8908    0.7010    0.7846       291\n",
            "           2     0.8557    0.7373    0.7921       354\n",
            "           3     0.8673    0.8250    0.8456       903\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8101    0.8477    0.8285       926\n",
            "           6     0.2000    0.5000    0.2857         2\n",
            "           7     0.7922    0.7969    0.7946       842\n",
            "           8     0.9524    0.7942    0.8661       277\n",
            "           9     0.9165    0.9450    0.9305      1219\n",
            "          10     0.8926    0.9821    0.9352      1117\n",
            "\n",
            "    accuracy                         0.8622      6272\n",
            "   macro avg     0.7268    0.7206    0.7155      6272\n",
            "weighted avg     0.8641    0.8622    0.8615      6272\n",
            "\n",
            "Best Intent Acc: 86.22 at Epoch: [4]\n",
            "Best F1 score: 86.95 at Epoch: [3]\n",
            "**************************************************\n",
            "1524it [10:48,  2.35it/s]\n",
            "196it [00:28,  6.98it/s]\n",
            "Epoch: [5/20], Intent Val Acc: 86.21 \t Slot F1 score: 87.53\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8308    0.7849    0.8072       344\n",
            "           1     0.8014    0.7629    0.7817       291\n",
            "           2     0.8673    0.7203    0.7870       354\n",
            "           3     0.8455    0.8370    0.8412       902\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8726    0.8247    0.8480       930\n",
            "           6     0.1111    0.5000    0.1818         2\n",
            "           7     0.7721    0.7867    0.7793       844\n",
            "           8     0.9489    0.8080    0.8728       276\n",
            "           9     0.9070    0.9524    0.9291      1218\n",
            "          10     0.8964    0.9811    0.9368      1111\n",
            "\n",
            "    accuracy                         0.8621      6272\n",
            "   macro avg     0.7139    0.7235    0.7059      6272\n",
            "weighted avg     0.8633    0.8621    0.8614      6272\n",
            "\n",
            "Best Intent Acc: 86.22 at Epoch: [4]\n",
            "Best F1 score: 87.53 at Epoch: [5]\n",
            "**************************************************\n",
            "1524it [10:50,  2.34it/s]\n",
            "196it [00:28,  6.92it/s]\n",
            "Epoch: [6/20], Intent Val Acc: 86.94 \t Slot F1 score: 87.40\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8567    0.7843    0.8189       343\n",
            "           1     0.7893    0.7674    0.7782       288\n",
            "           2     0.8836    0.7288    0.7988       354\n",
            "           3     0.8462    0.8808    0.8632       906\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8246    0.8504    0.8373       929\n",
            "           6     0.5000    0.5000    0.5000         2\n",
            "           7     0.8501    0.7595    0.8023       844\n",
            "           8     0.9700    0.8188    0.8880       276\n",
            "           9     0.9102    0.9530    0.9311      1213\n",
            "          10     0.8937    0.9785    0.9342      1117\n",
            "\n",
            "    accuracy                         0.8694      6272\n",
            "   macro avg     0.7568    0.7292    0.7411      6272\n",
            "weighted avg     0.8698    0.8694    0.8680      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.53 at Epoch: [5]\n",
            "**************************************************\n",
            "1524it [10:47,  2.35it/s]\n",
            "196it [00:28,  6.95it/s]\n",
            "Epoch: [7/20], Intent Val Acc: 86.61 \t Slot F1 score: 87.15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7959    0.8029    0.7994       340\n",
            "           1     0.8308    0.7397    0.7826       292\n",
            "           2     0.8938    0.7394    0.8093       353\n",
            "           3     0.8468    0.8664    0.8565       906\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8553    0.8414    0.8483       927\n",
            "           6     0.1000    0.5000    0.1667         2\n",
            "           7     0.8289    0.7790    0.8032       846\n",
            "           8     0.8980    0.8327    0.8642       275\n",
            "           9     0.9303    0.9326    0.9314      1216\n",
            "          10     0.8902    0.9812    0.9334      1115\n",
            "\n",
            "    accuracy                         0.8661      6272\n",
            "   macro avg     0.7155    0.7287    0.7086      6272\n",
            "weighted avg     0.8707    0.8661    0.8672      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.53 at Epoch: [5]\n",
            "**************************************************\n",
            "1524it [10:40,  2.38it/s]\n",
            "196it [00:27,  7.04it/s]\n",
            "Epoch: [8/20], Intent Val Acc: 86.56 \t Slot F1 score: 87.43\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8938    0.7676    0.8259       340\n",
            "           1     0.7568    0.7595    0.7581       291\n",
            "           2     0.9059    0.7365    0.8125       353\n",
            "           3     0.8486    0.8608    0.8546       905\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8272    0.8495    0.8382       930\n",
            "           6     0.1250    0.5000    0.2000         2\n",
            "           7     0.8312    0.7669    0.7978       841\n",
            "           8     0.9224    0.8159    0.8659       277\n",
            "           9     0.9057    0.9548    0.9296      1217\n",
            "          10     0.9018    0.9713    0.9353      1116\n",
            "\n",
            "    accuracy                         0.8656      6272\n",
            "   macro avg     0.7199    0.7257    0.7107      6272\n",
            "weighted avg     0.8681    0.8656    0.8654      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.53 at Epoch: [5]\n",
            "**************************************************\n",
            "1524it [10:39,  2.38it/s]\n",
            "196it [00:27,  7.05it/s]\n",
            "Epoch: [9/20], Intent Val Acc: 86.48 \t Slot F1 score: 87.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8447    0.7587    0.7994       344\n",
            "           1     0.7516    0.8007    0.7754       291\n",
            "           2     0.8733    0.7203    0.7895       354\n",
            "           3     0.8485    0.8456    0.8470       907\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8611    0.8332    0.8469       923\n",
            "           6     0.0833    0.5000    0.1429         2\n",
            "           7     0.7955    0.8031    0.7993       843\n",
            "           8     0.9456    0.8218    0.8794       275\n",
            "           9     0.9285    0.9368    0.9326      1219\n",
            "          10     0.8915    0.9811    0.9342      1114\n",
            "\n",
            "    accuracy                         0.8648      6272\n",
            "   macro avg     0.7112    0.7274    0.7042      6272\n",
            "weighted avg     0.8671    0.8648    0.8647      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:46,  2.36it/s]\n",
            "196it [00:28,  6.85it/s]\n",
            "Epoch: [10/20], Intent Val Acc: 86.40 \t Slot F1 score: 87.32\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8471    0.7755    0.8097       343\n",
            "           1     0.7426    0.7732    0.7576       291\n",
            "           2     0.9151    0.7025    0.7949       353\n",
            "           3     0.8757    0.8359    0.8554       902\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8405    0.8378    0.8392       931\n",
            "           6     0.1429    0.5000    0.2222         2\n",
            "           7     0.8014    0.7882    0.7947       845\n",
            "           8     0.9824    0.8051    0.8849       277\n",
            "           9     0.9005    0.9605    0.9295      1215\n",
            "          10     0.8912    0.9784    0.9328      1113\n",
            "\n",
            "    accuracy                         0.8640      6272\n",
            "   macro avg     0.7218    0.7234    0.7110      6272\n",
            "weighted avg     0.8670    0.8640    0.8636      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:47,  2.35it/s]\n",
            "196it [00:28,  6.90it/s]\n",
            "Epoch: [11/20], Intent Val Acc: 86.07 \t Slot F1 score: 87.41\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8885    0.7413    0.8082       344\n",
            "           1     0.7551    0.7655    0.7603       290\n",
            "           2     0.8344    0.7585    0.7946       352\n",
            "           3     0.8807    0.8077    0.8427       905\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8464    0.8373    0.8418       928\n",
            "           6     0.1250    0.5000    0.2000         2\n",
            "           7     0.7572    0.8167    0.7858       840\n",
            "           8     0.9091    0.8303    0.8679       277\n",
            "           9     0.9293    0.9286    0.9290      1218\n",
            "          10     0.8920    0.9839    0.9357      1116\n",
            "\n",
            "    accuracy                         0.8607      6272\n",
            "   macro avg     0.7107    0.7245    0.7060      6272\n",
            "weighted avg     0.8636    0.8607    0.8607      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:47,  2.35it/s]\n",
            "196it [00:28,  6.87it/s]\n",
            "Epoch: [12/20], Intent Val Acc: 86.64 \t Slot F1 score: 87.72\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8709    0.7668    0.8155       343\n",
            "           1     0.7081    0.7808    0.7427       292\n",
            "           2     0.9247    0.7309    0.8165       353\n",
            "           3     0.8707    0.8331    0.8515       905\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8736    0.8207    0.8463       926\n",
            "           6     0.0500    0.5000    0.0909         2\n",
            "           7     0.7789    0.8233    0.8005       843\n",
            "           8     0.9190    0.8225    0.8681       276\n",
            "           9     0.9260    0.9458    0.9358      1218\n",
            "          10     0.8970    0.9847    0.9388      1114\n",
            "\n",
            "    accuracy                         0.8664      6272\n",
            "   macro avg     0.7108    0.7281    0.7006      6272\n",
            "weighted avg     0.8715    0.8664    0.8672      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:47,  2.35it/s]\n",
            "196it [00:27,  7.01it/s]\n",
            "Epoch: [13/20], Intent Val Acc: 86.65 \t Slot F1 score: 87.41\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7994    0.7924    0.7959       342\n",
            "           1     0.7706    0.7363    0.7531       292\n",
            "           2     0.8851    0.7401    0.8062       354\n",
            "           3     0.8374    0.8642    0.8506       906\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8573    0.8369    0.8470       926\n",
            "           6     0.3333    0.5000    0.4000         2\n",
            "           7     0.8308    0.7755    0.8022       842\n",
            "           8     0.9404    0.8095    0.8701       273\n",
            "           9     0.9148    0.9508    0.9324      1219\n",
            "          10     0.8953    0.9812    0.9363      1116\n",
            "\n",
            "    accuracy                         0.8665      6272\n",
            "   macro avg     0.7331    0.7261    0.7267      6272\n",
            "weighted avg     0.8666    0.8665    0.8654      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "1524it [10:49,  2.35it/s]\n",
            "196it [00:28,  6.96it/s]\n",
            "Epoch: [14/20], Intent Val Acc: 85.92 \t Slot F1 score: 87.12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8328    0.7697    0.8000       343\n",
            "           1     0.7517    0.7388    0.7452       291\n",
            "           2     0.8767    0.7252    0.7938       353\n",
            "           3     0.8503    0.8466    0.8485       906\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8278    0.8422    0.8349       925\n",
            "           6     0.0588    0.5000    0.1053         2\n",
            "           7     0.8074    0.7767    0.7918       842\n",
            "           8     0.9383    0.8291    0.8803       275\n",
            "           9     0.9200    0.9351    0.9275      1218\n",
            "          10     0.9020    0.9722    0.9358      1117\n",
            "\n",
            "    accuracy                         0.8592      6272\n",
            "   macro avg     0.7060    0.7214    0.6966      6272\n",
            "weighted avg     0.8635    0.8592    0.8604      6272\n",
            "\n",
            "Best Intent Acc: 86.94 at Epoch: [6]\n",
            "Best F1 score: 87.95 at Epoch: [9]\n",
            "**************************************************\n",
            "373it [02:37,  2.36it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANenhdJcLQfW"
      },
      "source": [
        "# Hyperparameters Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQtK0JrxCZzJ"
      },
      "source": [
        "import random\n",
        "\n",
        "results = []\n",
        "for _ in range(10):\n",
        "    ne = 7\n",
        "    bs = random.choice([16])\n",
        "    wed = random.choice([100])\n",
        "    ehd = random.choice([192, 256])\n",
        "    lr = random.uniform(1e-4, 1e-2)\n",
        "\n",
        "    print(bs, wed, ehd)\n",
        "\n",
        "    !cd drive/MyDrive/Development/ID_in_CRS/Bi-Model-Intent-And-Slot && python train_args.py -te {ne} -bb {bs} -es {wed} -lhs {ehd}\n",
        "\n",
        "    print(\"#\" * 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9MobZuvFxVV"
      },
      "source": [
        "# Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uML1IhNbxDyH"
      },
      "source": [
        "!pip install fasttext > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHGuPIpyKqYh"
      },
      "source": [
        "import json\n",
        "import fasttext\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPcyk4BYK5GM"
      },
      "source": [
        "data_path = \"drive/MyDrive/Datasets/MultiWOZ_2.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Fpr3trKfNe"
      },
      "source": [
        "with open(f\"{data_path}/train.json\", \"r\") as json_file:\n",
        "    train_data = json.load(json_file)\n",
        "with open(f\"{data_path}/validation.json\", \"r\") as json_file:\n",
        "    val_data = json.load(json_file)\n",
        "with open(f\"{data_path}/test.json\", \"r\") as json_file:\n",
        "    test_data = json.load(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A75TgIDFKixc"
      },
      "source": [
        "intent_label = \"intents\"\n",
        "\n",
        "def read_data(data):\n",
        "    X, y = [], []\n",
        "\n",
        "    for id, dlg in data.items():\n",
        "        for trn in dlg:\n",
        "            if len(trn[intent_label]) == 1 and trn[\"speaker\"] == 0:\n",
        "                X.append(\" \".join(trn[\"words\"]))\n",
        "                y.append(trn[intent_label][0])\n",
        "\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = read_data(train_data)\n",
        "X_val, y_val = read_data(val_data)\n",
        "X_test, y_test = read_data(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnGf4hilPbu9",
        "outputId": "528d0cd1-cb56-4ebc-cb3e-26ae7eb9f235"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_val = encoder.transform(y_val)\n",
        "y_test = encoder.transform(y_test)\n",
        "\n",
        "{class_name: idx for idx, class_name in enumerate(encoder.classes_)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'book_hotel': 0,\n",
              " 'book_restaurant': 1,\n",
              " 'book_train': 2,\n",
              " 'find_attraction': 3,\n",
              " 'find_hospital': 4,\n",
              " 'find_hotel': 5,\n",
              " 'find_police': 6,\n",
              " 'find_restaurant': 7,\n",
              " 'find_taxi': 8,\n",
              " 'find_train': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_bXupE0FvLJ"
      },
      "source": [
        "def prepare_fasttext_file(filename, X, Y):\n",
        "    with open(f\"{filename}.txt\", \"w\") as txt_file:\n",
        "        for x, y in zip(X, Y):\n",
        "            txt_file.write(f\"__label__{y} {x}\\n\")\n",
        "\n",
        "prepare_fasttext_file(\"train\", X_train, y_train)\n",
        "prepare_fasttext_file(\"val\", X_val, y_val)\n",
        "prepare_fasttext_file(\"test\", X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbcgjNLDtR94",
        "outputId": "b29224dd-b7c5-48c1-b8c7-1558d1a755cc"
      },
      "source": [
        "import gc\n",
        "\n",
        "del train_data, X_train, y_train\n",
        "del val_data, X_val, y_val\n",
        "del test_data\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znDeWlnqKTN8"
      },
      "source": [
        "model = fasttext.train_supervised(\n",
        "    input=\"train.txt\",\n",
        "    autotuneValidationFile=\"val.txt\",\n",
        "    epoch=3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ZbdvXoLFVg",
        "outputId": "b87f33ba-87ea-4628-dd73-2d8ab31c99ee"
      },
      "source": [
        "preds, _ = model.predict(X_test)\n",
        "preds = [int(pred_label[0][-1]) for pred_label in preds]\n",
        "print(classification_report(y_test, preds, digits=4))\n",
        "print(confusion_matrix(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7339    0.7507    0.7422       349\n",
            "           1     0.8045    0.7329    0.7670       292\n",
            "           2     0.8525    0.7283    0.7855       357\n",
            "           3     0.8576    0.8764    0.8669       955\n",
            "           4     0.0000    0.0000    0.0000         0\n",
            "           5     0.8415    0.8527    0.8471       903\n",
            "           6     0.5000    0.5000    0.5000         2\n",
            "           7     0.8118    0.8000    0.8059       825\n",
            "           8     0.9368    0.8464    0.8893       280\n",
            "           9     0.9072    0.9537    0.9298      1230\n",
            "\n",
            "    accuracy                         0.8500      5193\n",
            "   macro avg     0.7246    0.7041    0.7134      5193\n",
            "weighted avg     0.8518    0.8500    0.8501      5193\n",
            "\n",
            "[[ 262   11   13    4    0   43    0   10    0    6]\n",
            " [  20  214   10    5    0    6    0   29    2    6]\n",
            " [  11   10  260    1    0    3    0    2    2   68]\n",
            " [   7    6    2  837    7   25    1   61    6    3]\n",
            " [   0    0    0    0    0    0    0    0    0    0]\n",
            " [  17    3    6   51    3  770    0   46    1    6]\n",
            " [   1    0    0    0    0    0    1    0    0    0]\n",
            " [  13   17    1   66    3   56    0  660    2    7]\n",
            " [   6    3    1    6    0    1    0    2  237   24]\n",
            " [  20    2   12    6    0   11    0    3    3 1173]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvl04Ft4u_0M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}